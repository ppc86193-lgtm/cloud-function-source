#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PC28ä¸šåŠ¡é€»è¾‘æå–å™¨
å…¨é¢æå–ç³»ç»Ÿä¸­çš„æ‰€æœ‰ä¸šåŠ¡é€»è¾‘ï¼ŒåŒ…æ‹¬ä»£ç é€»è¾‘å’Œæ•°æ®åº“ä¸­çš„ä¸šåŠ¡é€»è¾‘
ä¸ºç»Ÿä¸€ä¼˜åŒ–åšå‡†å¤‡
"""

import os
import json
import logging
import ast
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple, Set
from pathlib import Path
from google.cloud import bigquery
import pandas as pd

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BusinessLogicExtractor:
    """ä¸šåŠ¡é€»è¾‘æå–å™¨"""
    
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¸šåŠ¡é€»è¾‘åˆ†ç±»
        self.business_logic = {
            "lottery_logic": [],           # å½©ç¥¨é€»è¾‘
            "betting_logic": [],           # æŠ•æ³¨é€»è¾‘
            "payout_logic": [],            # èµ”ä»˜é€»è¾‘
            "risk_management": [],         # é£é™©ç®¡ç†
            "data_processing": [],         # æ•°æ®å¤„ç†
            "validation_rules": [],        # éªŒè¯è§„åˆ™
            "calculation_formulas": [],    # è®¡ç®—å…¬å¼
            "business_rules": [],          # ä¸šåŠ¡è§„åˆ™
            "workflow_logic": [],          # å·¥ä½œæµé€»è¾‘
            "integration_logic": []        # é›†æˆé€»è¾‘
        }
        
        # æ•°æ®åº“ä¸šåŠ¡é€»è¾‘
        self.database_logic = {
            "table_relationships": [],     # è¡¨å…³ç³»
            "business_constraints": [],    # ä¸šåŠ¡çº¦æŸ
            "calculated_fields": [],       # è®¡ç®—å­—æ®µ
            "triggers_procedures": [],     # è§¦å‘å™¨å’Œå­˜å‚¨è¿‡ç¨‹
            "views_logic": [],            # è§†å›¾é€»è¾‘
            "indexes_optimization": []     # ç´¢å¼•ä¼˜åŒ–
        }
        
        # åˆå§‹åŒ–BigQueryå®¢æˆ·ç«¯
        try:
            self.bq_client = bigquery.Client()
            logger.info("âœ… BigQueryå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ BigQueryå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.bq_client = None
    
    def extract_all_business_logic(self) -> Dict[str, Any]:
        """æå–æ‰€æœ‰ä¸šåŠ¡é€»è¾‘"""
        logger.info("ğŸ” å¼€å§‹æå–PC28ç³»ç»Ÿçš„æ‰€æœ‰ä¸šåŠ¡é€»è¾‘...")
        
        # 1. æå–ä»£ç ä¸­çš„ä¸šåŠ¡é€»è¾‘
        self._extract_code_business_logic()
        
        # 2. æå–æ•°æ®åº“ä¸­çš„ä¸šåŠ¡é€»è¾‘
        self._extract_database_business_logic()
        
        # 3. åˆ†æä¸šåŠ¡é€»è¾‘å…³ç³»
        relationships = self._analyze_business_relationships()
        
        # 4. è¯†åˆ«ä¼˜åŒ–æœºä¼š
        optimization_opportunities = self._identify_optimization_opportunities()
        
        # 5. ç”Ÿæˆä¸šåŠ¡é€»è¾‘æŠ¥å‘Š
        extraction_report = {
            "extraction_metadata": {
                "timestamp": self.timestamp,
                "base_path": str(self.base_path),
                "extraction_scope": "comprehensive"
            },
            "code_business_logic": self.business_logic,
            "database_business_logic": self.database_logic,
            "business_relationships": relationships,
            "optimization_opportunities": optimization_opportunities,
            "unified_optimization_plan": self._create_unified_optimization_plan()
        }
        
        return extraction_report
    
    def _extract_code_business_logic(self):
        """æå–ä»£ç ä¸­çš„ä¸šåŠ¡é€»è¾‘"""
        logger.info("ğŸ“ æå–ä»£ç ä¸šåŠ¡é€»è¾‘...")
        
        # ä¸šåŠ¡é€»è¾‘å…³é”®è¯æ˜ å°„
        business_keywords = {
            "lottery_logic": [
                "lottery", "draw", "winning", "number", "result", "prize",
                "jackpot", "combination", "random", "generate"
            ],
            "betting_logic": [
                "bet", "wager", "stake", "odds", "prediction", "choice",
                "selection", "ticket", "entry", "submit"
            ],
            "payout_logic": [
                "payout", "payment", "reward", "prize", "winning", "amount",
                "calculate", "distribution", "settlement", "commission"
            ],
            "risk_management": [
                "risk", "limit", "threshold", "validation", "check", "verify",
                "security", "fraud", "detection", "monitoring"
            ],
            "data_processing": [
                "process", "transform", "aggregate", "filter", "sort",
                "group", "merge", "join", "update", "sync"
            ],
            "validation_rules": [
                "validate", "verify", "check", "rule", "constraint", "format",
                "pattern", "required", "optional", "condition"
            ],
            "calculation_formulas": [
                "calculate", "compute", "formula", "algorithm", "math",
                "sum", "average", "percentage", "ratio", "rate"
            ],
            "business_rules": [
                "rule", "policy", "condition", "requirement", "specification",
                "criteria", "standard", "guideline", "regulation"
            ],
            "workflow_logic": [
                "workflow", "process", "step", "stage", "phase", "sequence",
                "order", "flow", "pipeline", "chain"
            ],
            "integration_logic": [
                "integration", "api", "service", "client", "connection",
                "interface", "endpoint", "request", "response"
            ]
        }
        
        # æ‰«æPythonæ–‡ä»¶
        python_files = list(self.base_path.rglob("*.py"))
        
        # æ’é™¤ç›®å½•
        exclude_dirs = {
            "venv", "env", ".venv", ".env", "node_modules", 
            "__pycache__", ".git", "site-packages", "dist-packages"
        }
        
        for file_path in python_files:
            # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
            should_exclude = False
            for part in file_path.parts:
                if part in exclude_dirs or part.startswith('.'):
                    should_exclude = True
                    break
            
            if should_exclude:
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æAST
                try:
                    tree = ast.parse(content)
                    self._analyze_ast_for_business_logic(tree, file_path, content, business_keywords)
                except SyntaxError:
                    # å¦‚æœASTè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†æ
                    self._analyze_content_for_business_logic(content, file_path, business_keywords)
                
            except Exception as e:
                logger.warning(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def _analyze_ast_for_business_logic(self, tree: ast.AST, file_path: Path, content: str, keywords: Dict[str, List[str]]):
        """é€šè¿‡ASTåˆ†æä¸šåŠ¡é€»è¾‘"""
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                func_info = {
                    "type": "function",
                    "name": node.name,
                    "file_path": str(file_path),
                    "line_number": node.lineno,
                    "docstring": ast.get_docstring(node),
                    "parameters": [arg.arg for arg in node.args.args],
                    "business_indicators": []
                }
                
                # åˆ†æå‡½æ•°åå’Œæ–‡æ¡£å­—ç¬¦ä¸²
                func_text = (node.name + " " + (func_info["docstring"] or "")).lower()
                
                # è·å–å‡½æ•°ä½“ä»£ç 
                func_lines = content.split('\n')[node.lineno-1:node.end_lineno if hasattr(node, 'end_lineno') else node.lineno+10]
                func_body = '\n'.join(func_lines).lower()
                
                # åˆ†ç±»ä¸šåŠ¡é€»è¾‘
                for category, category_keywords in keywords.items():
                    matches = []
                    for keyword in category_keywords:
                        if keyword in func_text or keyword in func_body:
                            matches.append(keyword)
                    
                    if matches:
                        func_info["business_indicators"] = matches
                        func_info["category"] = category
                        func_info["confidence"] = len(matches) / len(category_keywords)
                        self.business_logic[category].append(func_info)
                        break
            
            elif isinstance(node, ast.ClassDef):
                class_info = {
                    "type": "class",
                    "name": node.name,
                    "file_path": str(file_path),
                    "line_number": node.lineno,
                    "docstring": ast.get_docstring(node),
                    "methods": [],
                    "business_indicators": []
                }
                
                # åˆ†æç±»åå’Œæ–‡æ¡£å­—ç¬¦ä¸²
                class_text = (node.name + " " + (class_info["docstring"] or "")).lower()
                
                # åˆ†ç±»ä¸šåŠ¡é€»è¾‘
                for category, category_keywords in keywords.items():
                    matches = []
                    for keyword in category_keywords:
                        if keyword in class_text:
                            matches.append(keyword)
                    
                    if matches:
                        class_info["business_indicators"] = matches
                        class_info["category"] = category
                        class_info["confidence"] = len(matches) / len(category_keywords)
                        
                        # åˆ†æç±»ä¸­çš„æ–¹æ³•
                        for item in node.body:
                            if isinstance(item, ast.FunctionDef):
                                method_info = {
                                    "name": item.name,
                                    "line_number": item.lineno,
                                    "docstring": ast.get_docstring(item)
                                }
                                class_info["methods"].append(method_info)
                        
                        self.business_logic[category].append(class_info)
                        break
    
    def _analyze_content_for_business_logic(self, content: str, file_path: Path, keywords: Dict[str, List[str]]):
        """é€šè¿‡å†…å®¹åˆ†æä¸šåŠ¡é€»è¾‘ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            line_lower = line.lower().strip()
            
            # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
            if not line_lower or line_lower.startswith('#'):
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸šåŠ¡é€»è¾‘å…³é”®è¯
            for category, category_keywords in keywords.items():
                matches = []
                for keyword in category_keywords:
                    if keyword in line_lower:
                        matches.append(keyword)
                
                if matches:
                    logic_info = {
                        "type": "code_line",
                        "content": line.strip(),
                        "file_path": str(file_path),
                        "line_number": i + 1,
                        "business_indicators": matches,
                        "category": category,
                        "confidence": len(matches) / len(category_keywords)
                    }
                    
                    self.business_logic[category].append(logic_info)
    
    def _extract_database_business_logic(self):
        """æå–æ•°æ®åº“ä¸­çš„ä¸šåŠ¡é€»è¾‘"""
        logger.info("ğŸ—„ï¸ æå–æ•°æ®åº“ä¸šåŠ¡é€»è¾‘...")
        
        if not self.bq_client:
            logger.warning("âš ï¸ æ— æ³•è¿æ¥BigQueryï¼Œè·³è¿‡æ•°æ®åº“ä¸šåŠ¡é€»è¾‘æå–")
            return
        
        try:
            # è·å–æ‰€æœ‰æ•°æ®é›†å’Œè¡¨
            datasets = list(self.bq_client.list_datasets())
            
            for dataset in datasets:
                dataset_id = dataset.dataset_id
                logger.info(f"ğŸ“Š åˆ†ææ•°æ®é›†: {dataset_id}")
                
                # è·å–æ•°æ®é›†ä¸­çš„æ‰€æœ‰è¡¨
                tables = list(self.bq_client.list_tables(dataset_id))
                
                for table in tables:
                    table_id = table.table_id
                    full_table_id = f"{dataset_id}.{table_id}"
                    
                    try:
                        # è·å–è¡¨ç»“æ„
                        table_ref = self.bq_client.get_table(full_table_id)
                        
                        # åˆ†æè¡¨çš„ä¸šåŠ¡é€»è¾‘
                        self._analyze_table_business_logic(table_ref, full_table_id)
                        
                    except Exception as e:
                        logger.warning(f"åˆ†æè¡¨å¤±è´¥ {full_table_id}: {e}")
        
        except Exception as e:
            logger.error(f"æå–æ•°æ®åº“ä¸šåŠ¡é€»è¾‘å¤±è´¥: {e}")
    
    def _analyze_table_business_logic(self, table_ref, full_table_id: str):
        """åˆ†æå•ä¸ªè¡¨çš„ä¸šåŠ¡é€»è¾‘"""
        
        table_info = {
            "table_id": full_table_id,
            "table_name": table_ref.table_id,
            "description": table_ref.description,
            "num_rows": table_ref.num_rows,
            "num_bytes": table_ref.num_bytes,
            "created": table_ref.created.isoformat() if table_ref.created else None,
            "modified": table_ref.modified.isoformat() if table_ref.modified else None,
            "fields": [],
            "business_indicators": []
        }
        
        # åˆ†æå­—æ®µ
        for field in table_ref.schema:
            field_info = {
                "name": field.name,
                "field_type": field.field_type,
                "mode": field.mode,
                "description": field.description,
                "business_meaning": self._infer_business_meaning(field.name, field.description)
            }
            table_info["fields"].append(field_info)
        
        # æ ¹æ®è¡¨åå’Œå­—æ®µæ¨æ–­ä¸šåŠ¡é€»è¾‘ç±»å‹
        table_name_lower = table_ref.table_id.lower()
        
        # ä¸šåŠ¡é€»è¾‘åˆ†ç±»
        if any(keyword in table_name_lower for keyword in ["lottery", "draw", "winning", "result"]):
            table_info["business_category"] = "lottery_logic"
            self.database_logic["table_relationships"].append(table_info)
        elif any(keyword in table_name_lower for keyword in ["bet", "wager", "stake", "ticket"]):
            table_info["business_category"] = "betting_logic"
            self.database_logic["table_relationships"].append(table_info)
        elif any(keyword in table_name_lower for keyword in ["payout", "payment", "reward", "prize"]):
            table_info["business_category"] = "payout_logic"
            self.database_logic["table_relationships"].append(table_info)
        elif any(keyword in table_name_lower for keyword in ["user", "customer", "account", "profile"]):
            table_info["business_category"] = "user_management"
            self.database_logic["table_relationships"].append(table_info)
        elif any(keyword in table_name_lower for keyword in ["log", "audit", "history", "track"]):
            table_info["business_category"] = "audit_tracking"
            self.database_logic["table_relationships"].append(table_info)
        else:
            table_info["business_category"] = "general"
            self.database_logic["table_relationships"].append(table_info)
        
        # åˆ†æè®¡ç®—å­—æ®µ
        calculated_fields = []
        for field in table_info["fields"]:
            if any(keyword in field["name"].lower() for keyword in ["calc", "computed", "derived", "total", "sum", "avg"]):
                calculated_fields.append({
                    "table_id": full_table_id,
                    "field_name": field["name"],
                    "field_type": field["field_type"],
                    "business_meaning": field["business_meaning"]
                })
        
        if calculated_fields:
            self.database_logic["calculated_fields"].extend(calculated_fields)
    
    def _infer_business_meaning(self, field_name: str, field_description: str) -> str:
        """æ¨æ–­å­—æ®µçš„ä¸šåŠ¡å«ä¹‰"""
        
        field_name_lower = field_name.lower()
        description_lower = (field_description or "").lower()
        
        # ä¸šåŠ¡å«ä¹‰æ˜ å°„
        business_meanings = {
            "user_id": "ç”¨æˆ·æ ‡è¯†",
            "customer_id": "å®¢æˆ·æ ‡è¯†", 
            "bet_id": "æŠ•æ³¨æ ‡è¯†",
            "lottery_id": "å½©ç¥¨æ ‡è¯†",
            "amount": "é‡‘é¢",
            "balance": "ä½™é¢",
            "timestamp": "æ—¶é—´æˆ³",
            "status": "çŠ¶æ€",
            "result": "ç»“æœ",
            "winning": "ä¸­å¥–",
            "payout": "èµ”ä»˜",
            "odds": "èµ”ç‡",
            "commission": "ä½£é‡‘",
            "risk": "é£é™©",
            "limit": "é™åˆ¶"
        }
        
        # åŒ¹é…ä¸šåŠ¡å«ä¹‰
        for keyword, meaning in business_meanings.items():
            if keyword in field_name_lower or keyword in description_lower:
                return meaning
        
        return "æœªçŸ¥ä¸šåŠ¡å«ä¹‰"
    
    def _analyze_business_relationships(self) -> Dict[str, Any]:
        """åˆ†æä¸šåŠ¡é€»è¾‘å…³ç³»"""
        logger.info("ğŸ”— åˆ†æä¸šåŠ¡é€»è¾‘å…³ç³»...")
        
        relationships = {
            "code_to_database": [],
            "cross_category": [],
            "dependency_chains": [],
            "integration_points": []
        }
        
        # åˆ†æä»£ç ä¸æ•°æ®åº“çš„å…³ç³»
        for category, code_logic in self.business_logic.items():
            for logic_item in code_logic:
                # æ£€æŸ¥ä»£ç ä¸­æ˜¯å¦å¼•ç”¨äº†æ•°æ®åº“è¡¨
                for db_table in self.database_logic["table_relationships"]:
                    table_name = db_table["table_name"].lower()
                    
                    # æ£€æŸ¥å‡½æ•°åã€ç±»åæˆ–å†…å®¹ä¸­æ˜¯å¦åŒ…å«è¡¨å
                    logic_content = ""
                    if logic_item["type"] == "function":
                        logic_content = logic_item["name"].lower()
                    elif logic_item["type"] == "class":
                        logic_content = logic_item["name"].lower()
                    elif logic_item["type"] == "code_line":
                        logic_content = logic_item["content"].lower()
                    
                    if table_name in logic_content or any(part in logic_content for part in table_name.split("_")):
                        relationships["code_to_database"].append({
                            "code_logic": logic_item,
                            "database_table": db_table,
                            "relationship_type": "references"
                        })
        
        return relationships
    
    def _identify_optimization_opportunities(self) -> Dict[str, Any]:
        """è¯†åˆ«ä¼˜åŒ–æœºä¼š"""
        logger.info("ğŸ¯ è¯†åˆ«ä¼˜åŒ–æœºä¼š...")
        
        opportunities = {
            "redundant_logic": [],
            "performance_bottlenecks": [],
            "data_optimization": [],
            "code_consolidation": [],
            "unified_improvements": []
        }
        
        # è¯†åˆ«å†—ä½™é€»è¾‘
        logic_signatures = {}
        for category, logic_items in self.business_logic.items():
            for item in logic_items:
                # åˆ›å»ºé€»è¾‘ç­¾å
                signature = self._create_logic_signature(item)
                
                if signature in logic_signatures:
                    opportunities["redundant_logic"].append({
                        "signature": signature,
                        "original": logic_signatures[signature],
                        "duplicate": item,
                        "optimization_potential": "high"
                    })
                else:
                    logic_signatures[signature] = item
        
        # è¯†åˆ«æ•°æ®ä¼˜åŒ–æœºä¼š
        table_analysis = {}
        for table in self.database_logic["table_relationships"]:
            table_size = table.get("num_bytes", 0)
            table_rows = table.get("num_rows", 0)
            
            if table_size > 1000000000:  # 1GBä»¥ä¸Šçš„è¡¨
                opportunities["data_optimization"].append({
                    "table_id": table["table_id"],
                    "size_bytes": table_size,
                    "num_rows": table_rows,
                    "optimization_type": "large_table_optimization",
                    "priority": "high"
                })
        
        # è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
        for category, logic_items in self.business_logic.items():
            if len(logic_items) > 20:  # é€»è¾‘è¿‡å¤šçš„ç±»åˆ«
                opportunities["performance_bottlenecks"].append({
                    "category": category,
                    "logic_count": len(logic_items),
                    "optimization_type": "logic_consolidation",
                    "priority": "medium"
                })
        
        return opportunities
    
    def _create_logic_signature(self, logic_item: Dict[str, Any]) -> str:
        """åˆ›å»ºé€»è¾‘ç­¾åç”¨äºè¯†åˆ«é‡å¤"""
        
        if logic_item["type"] == "function":
            return f"func_{logic_item['name']}_{len(logic_item.get('parameters', []))}"
        elif logic_item["type"] == "class":
            return f"class_{logic_item['name']}_{len(logic_item.get('methods', []))}"
        elif logic_item["type"] == "code_line":
            # ç®€åŒ–ä»£ç è¡Œï¼Œç§»é™¤å˜é‡å
            simplified = re.sub(r'\b\w+\s*=', 'var=', logic_item["content"])
            return f"line_{hash(simplified) % 10000}"
        
        return "unknown"
    
    def _create_unified_optimization_plan(self) -> Dict[str, Any]:
        """åˆ›å»ºç»Ÿä¸€ä¼˜åŒ–è®¡åˆ’"""
        logger.info("ğŸ“‹ åˆ›å»ºç»Ÿä¸€ä¼˜åŒ–è®¡åˆ’...")
        
        plan = {
            "optimization_phases": [
                {
                    "phase": 1,
                    "name": "ä»£ç é€»è¾‘ä¼˜åŒ–",
                    "description": "ä¼˜åŒ–é‡å¤å’Œå†—ä½™çš„ä¸šåŠ¡é€»è¾‘ä»£ç ",
                    "priority": "high",
                    "estimated_impact": "medium"
                },
                {
                    "phase": 2,
                    "name": "æ•°æ®åº“ç»“æ„ä¼˜åŒ–",
                    "description": "ä¼˜åŒ–è¡¨ç»“æ„ã€ç´¢å¼•å’ŒæŸ¥è¯¢æ€§èƒ½",
                    "priority": "high", 
                    "estimated_impact": "high"
                },
                {
                    "phase": 3,
                    "name": "ä¸šåŠ¡æµç¨‹æ•´åˆ",
                    "description": "æ•´åˆç›¸å…³ä¸šåŠ¡é€»è¾‘ï¼Œå‡å°‘é‡å¤å¤„ç†",
                    "priority": "medium",
                    "estimated_impact": "medium"
                },
                {
                    "phase": 4,
                    "name": "æ€§èƒ½ç›‘æ§ä¼˜åŒ–",
                    "description": "å»ºç«‹æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨ä¼˜åŒ–æœºåˆ¶",
                    "priority": "medium",
                    "estimated_impact": "low"
                }
            ],
            "optimization_targets": {
                "code_reduction": "å‡å°‘20%çš„å†—ä½™ä»£ç ",
                "performance_improvement": "æå‡30%çš„æŸ¥è¯¢æ€§èƒ½",
                "storage_optimization": "å‡å°‘15%çš„å­˜å‚¨ç©ºé—´",
                "maintenance_efficiency": "æå‡50%çš„ç»´æŠ¤æ•ˆç‡"
            },
            "risk_mitigation": [
                "åœ¨ä¼˜åŒ–å‰å»ºç«‹å®Œæ•´çš„æµ‹è¯•åŸºçº¿",
                "åˆ†é˜¶æ®µæ‰§è¡Œä¼˜åŒ–ï¼Œæ¯é˜¶æ®µéªŒè¯ç³»ç»Ÿç¨³å®šæ€§",
                "ä¿ç•™åŸå§‹é€»è¾‘å¤‡ä»½ï¼Œæ”¯æŒå¿«é€Ÿå›æ»š",
                "å»ºç«‹ç›‘æ§æœºåˆ¶ï¼Œå®æ—¶è·Ÿè¸ªä¼˜åŒ–æ•ˆæœ"
            ]
        }
        
        return plan
    
    def save_business_logic_report(self, report: Dict[str, Any]):
        """ä¿å­˜ä¸šåŠ¡é€»è¾‘æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜JSONæŠ¥å‘Š
        json_file = f"pc28_business_logic_extraction_report_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        md_file = f"pc28_business_logic_extraction_report_{timestamp}.md"
        self._generate_markdown_report(report, md_file)
        
        logger.info(f"ğŸ“„ ä¸šåŠ¡é€»è¾‘æå–æŠ¥å‘Šå·²ä¿å­˜:")
        logger.info(f"  JSON: {json_file}")
        logger.info(f"  Markdown: {md_file}")
        
        return json_file, md_file
    
    def _generate_markdown_report(self, report: Dict[str, Any], file_path: str):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        
        metadata = report["extraction_metadata"]
        code_logic = report["code_business_logic"]
        db_logic = report["database_business_logic"]
        relationships = report["business_relationships"]
        opportunities = report["optimization_opportunities"]
        plan = report["unified_optimization_plan"]
        
        content = f"""# PC28ä¸šåŠ¡é€»è¾‘æå–æŠ¥å‘Š

## ğŸ“Š æå–æ¦‚è§ˆ

**æå–æ—¶é—´**: {metadata['timestamp']}
**åŸºç¡€è·¯å¾„**: {metadata['base_path']}
**æå–èŒƒå›´**: {metadata['extraction_scope']}

## ğŸ’¼ ä»£ç ä¸šåŠ¡é€»è¾‘

"""
        
        total_code_logic = sum(len(items) for items in code_logic.values())
        content += f"**æ€»è®¡**: {total_code_logic} ä¸ªä¸šåŠ¡é€»è¾‘é¡¹\n\n"
        
        for category, items in code_logic.items():
            if items:
                category_name = category.replace("_", " ").title()
                content += f"""
### {category_name}
**æ•°é‡**: {len(items)}

**ä¸»è¦é¡¹ç›®**:
"""
                for item in items[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    if item["type"] == "function":
                        content += f"- å‡½æ•°: `{item['name']}` ({Path(item['file_path']).name}:{item['line_number']})\n"
                    elif item["type"] == "class":
                        content += f"- ç±»: `{item['name']}` ({Path(item['file_path']).name}:{item['line_number']})\n"
                    elif item["type"] == "code_line":
                        content += f"- ä»£ç : `{item['content'][:50]}...` ({Path(item['file_path']).name}:{item['line_number']})\n"
                
                if len(items) > 5:
                    content += f"- ... è¿˜æœ‰ {len(items) - 5} ä¸ªé¡¹ç›®\n"
        
        content += f"""
## ğŸ—„ï¸ æ•°æ®åº“ä¸šåŠ¡é€»è¾‘

**è¡¨å…³ç³»**: {len(db_logic['table_relationships'])} ä¸ªè¡¨
**è®¡ç®—å­—æ®µ**: {len(db_logic['calculated_fields'])} ä¸ªå­—æ®µ

### ä¸»è¦ä¸šåŠ¡è¡¨
"""
        
        # æŒ‰ä¸šåŠ¡ç±»åˆ«åˆ†ç»„æ˜¾ç¤ºè¡¨
        table_categories = {}
        for table in db_logic["table_relationships"]:
            category = table.get("business_category", "general")
            if category not in table_categories:
                table_categories[category] = []
            table_categories[category].append(table)
        
        for category, tables in table_categories.items():
            category_name = category.replace("_", " ").title()
            content += f"""
#### {category_name}
"""
            for table in tables[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                size_mb = table.get("num_bytes", 0) / (1024 * 1024) if table.get("num_bytes") else 0
                content += f"- `{table['table_name']}`: {table.get('num_rows', 0):,} è¡Œ, {size_mb:.1f} MB\n"
            
            if len(tables) > 5:
                content += f"- ... è¿˜æœ‰ {len(tables) - 5} ä¸ªè¡¨\n"
        
        content += f"""
## ğŸ”— ä¸šåŠ¡é€»è¾‘å…³ç³»

**ä»£ç -æ•°æ®åº“å…³ç³»**: {len(relationships['code_to_database'])} ä¸ªå…³è”
**è·¨ç±»åˆ«å…³ç³»**: {len(relationships['cross_category'])} ä¸ªå…³è”

## ğŸ¯ ä¼˜åŒ–æœºä¼š

### å†—ä½™é€»è¾‘
**å‘ç°**: {len(opportunities['redundant_logic'])} ä¸ªå†—ä½™é¡¹
"""
        
        for redundant in opportunities["redundant_logic"][:3]:
            content += f"- ç­¾å: `{redundant['signature']}` (ä¼˜åŒ–æ½œåŠ›: {redundant['optimization_potential']})\n"
        
        content += f"""
### æ•°æ®ä¼˜åŒ–
**å¤§è¡¨ä¼˜åŒ–**: {len(opportunities['data_optimization'])} ä¸ªè¡¨éœ€è¦ä¼˜åŒ–
"""
        
        for data_opt in opportunities["data_optimization"][:3]:
            size_gb = data_opt["size_bytes"] / (1024 * 1024 * 1024)
            content += f"- `{data_opt['table_id']}`: {size_gb:.2f} GB, {data_opt['num_rows']:,} è¡Œ\n"
        
        content += f"""
### æ€§èƒ½ç“¶é¢ˆ
**é€»è¾‘é›†ä¸­**: {len(opportunities['performance_bottlenecks'])} ä¸ªç±»åˆ«éœ€è¦ä¼˜åŒ–
"""
        
        for bottleneck in opportunities["performance_bottlenecks"]:
            content += f"- {bottleneck['category']}: {bottleneck['logic_count']} ä¸ªé€»è¾‘é¡¹\n"
        
        content += f"""
## ğŸ“‹ ç»Ÿä¸€ä¼˜åŒ–è®¡åˆ’

### ä¼˜åŒ–é˜¶æ®µ
"""
        
        for phase in plan["optimization_phases"]:
            content += f"""
#### é˜¶æ®µ {phase['phase']}: {phase['name']}
- **æè¿°**: {phase['description']}
- **ä¼˜å…ˆçº§**: {phase['priority']}
- **é¢„æœŸå½±å“**: {phase['estimated_impact']}
"""
        
        content += f"""
### ä¼˜åŒ–ç›®æ ‡
"""
        
        for target, description in plan["optimization_targets"].items():
            content += f"- **{target.replace('_', ' ').title()}**: {description}\n"
        
        content += f"""
### é£é™©ç¼“è§£
"""
        
        for risk in plan["risk_mitigation"]:
            content += f"- {risk}\n"
        
        content += f"""
## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **è¿è¡ŒåŸºçº¿æµ‹è¯•** - å»ºç«‹ä¼˜åŒ–å‰çš„æ€§èƒ½å’ŒåŠŸèƒ½åŸºå‡†
2. **æ‰§è¡Œé˜¶æ®µ1ä¼˜åŒ–** - å¼€å§‹ä»£ç é€»è¾‘ä¼˜åŒ–
3. **éªŒè¯ä¼˜åŒ–æ•ˆæœ** - ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§å’Œæ€§èƒ½æå‡
4. **ç»§ç»­åç»­é˜¶æ®µ** - æŒ‰è®¡åˆ’æ‰§è¡Œæ•°æ®åº“å’Œæµç¨‹ä¼˜åŒ–
5. **å»ºç«‹ç›‘æ§æœºåˆ¶** - æŒç»­è·Ÿè¸ªä¼˜åŒ–æ•ˆæœ

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().isoformat()}
**ç‰ˆæœ¬**: 1.0
"""
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ’¼ PC28ä¸šåŠ¡é€»è¾‘æå–å™¨")
    print("=" * 60)
    print("ğŸ¯ ç›®æ ‡ï¼šå…¨é¢æå–ç³»ç»Ÿä¸­çš„æ‰€æœ‰ä¸šåŠ¡é€»è¾‘")
    print("ğŸ“‹ èŒƒå›´ï¼šä»£ç é€»è¾‘ + æ•°æ®åº“é€»è¾‘ + ä¸šåŠ¡å…³ç³»")
    print("ğŸ”§ ç”¨é€”ï¼šä¸ºç»Ÿä¸€ä¼˜åŒ–æä¾›å®Œæ•´çš„ä¸šåŠ¡é€»è¾‘åŸºç¡€")
    print("=" * 60)
    
    extractor = BusinessLogicExtractor()
    
    try:
        # æå–æ‰€æœ‰ä¸šåŠ¡é€»è¾‘
        extraction_report = extractor.extract_all_business_logic()
        
        # ä¿å­˜æŠ¥å‘Š
        json_file, md_file = extractor.save_business_logic_report(extraction_report)
        
        # æ˜¾ç¤ºæ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š ä¸šåŠ¡é€»è¾‘æå–æ‘˜è¦")
        print("=" * 60)
        
        code_logic = extraction_report["code_business_logic"]
        db_logic = extraction_report["database_business_logic"]
        opportunities = extraction_report["optimization_opportunities"]
        
        total_code_logic = sum(len(items) for items in code_logic.values())
        total_tables = len(db_logic["table_relationships"])
        total_opportunities = sum(len(items) for items in opportunities.values())
        
        print(f"\nğŸ’¼ ä»£ç ä¸šåŠ¡é€»è¾‘: {total_code_logic} ä¸ª")
        print(f"ğŸ—„ï¸ æ•°æ®åº“è¡¨: {total_tables} ä¸ª")
        print(f"ğŸ¯ ä¼˜åŒ–æœºä¼š: {total_opportunities} ä¸ª")
        
        print(f"\nğŸ“Š ä»£ç é€»è¾‘åˆ†å¸ƒ:")
        for category, items in code_logic.items():
            if items:
                category_name = category.replace("_", " ").title()
                print(f"   {category_name}: {len(items)} ä¸ª")
        
        print(f"\nğŸ—„ï¸ æ•°æ®åº“é€»è¾‘:")
        print(f"   è¡¨å…³ç³»: {len(db_logic['table_relationships'])} ä¸ª")
        print(f"   è®¡ç®—å­—æ®µ: {len(db_logic['calculated_fields'])} ä¸ª")
        
        print(f"\nğŸ¯ ä¸»è¦ä¼˜åŒ–æœºä¼š:")
        print(f"   å†—ä½™é€»è¾‘: {len(opportunities['redundant_logic'])} ä¸ª")
        print(f"   æ•°æ®ä¼˜åŒ–: {len(opportunities['data_optimization'])} ä¸ª")
        print(f"   æ€§èƒ½ç“¶é¢ˆ: {len(opportunities['performance_bottlenecks'])} ä¸ª")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {md_file}")
        print("\nğŸ‰ ä¸šåŠ¡é€»è¾‘æå–å®Œæˆï¼ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿›è¡Œç»Ÿä¸€ä¼˜åŒ–ã€‚")
        
    except Exception as e:
        logger.error(f"ä¸šåŠ¡é€»è¾‘æå–å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()