#!/usr/bin/env python3
"""
ç³»ç»ŸçŠ¶æ€æ€»ç»“å’Œè¿è¡ŒçŠ¶æ€æ£€æŸ¥
æ£€æŸ¥æ‰€æœ‰è¿è¡Œä¸­çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿå¹¶ç”ŸæˆçŠ¶æ€æŠ¥å‘Š
"""

import json
import os
import sqlite3
import psutil
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SystemStatusChecker:
    def __init__(self):
        self.project_root = "/Users/a606/cloud_function_source"
        self.local_data_dir = "/Users/a606/cloud_function_source/local_data"
        
    def check_running_processes(self) -> Dict[str, Any]:
        """æ£€æŸ¥è¿è¡Œä¸­çš„Pythonè¿›ç¨‹"""
        running_processes = {
            "total_python_processes": 0,
            "system_processes": [],
            "resource_usage": {}
        }
        
        try:
            system_scripts = [
                "automated_compliance_checker.py",
                "enhanced_data_flow_system.py", 
                "monitoring_system.py",
                "cloud_to_local_sync_system.py",
                "data_consistency_checker.py"
            ]
            
            for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'cpu_percent', 'memory_percent']):
                try:
                    if proc.info['name'] == 'python3' and proc.info['cmdline']:
                        cmdline = ' '.join(proc.info['cmdline'])
                        
                        for script in system_scripts:
                            if script in cmdline:
                                running_processes["system_processes"].append({
                                    "script": script,
                                    "pid": proc.info['pid'],
                                    "cpu_percent": proc.info['cpu_percent'],
                                    "memory_percent": proc.info['memory_percent'],
                                    "status": "running"
                                })
                                break
                        
                        if 'python3' in cmdline:
                            running_processes["total_python_processes"] += 1
                            
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            # ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
            running_processes["resource_usage"] = {
                "cpu_percent": psutil.cpu_percent(interval=1),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_usage_percent": psutil.disk_usage('/').percent,
                "disk_free_gb": psutil.disk_usage('/').free / (1024**3)
            }
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥è¿è¡Œè¿›ç¨‹å¤±è´¥: {e}")
        
        return running_processes
    
    def check_database_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“çŠ¶æ€"""
        db_status = {
            "databases": [],
            "total_size_mb": 0.0,
            "health_status": "unknown"
        }
        
        try:
            db_files = [
                "monitoring.db",
                "consistency_checks.db", 
                "sync_metadata.db",
                "export_verification.db",
                "ai_analysis.db",
                "pc28_complete_mirror.db"
            ]
            
            for db_file in db_files:
                db_path = os.path.join(self.local_data_dir, db_file)
                
                if os.path.exists(db_path):
                    file_size = os.path.getsize(db_path) / (1024 * 1024)  # MB
                    
                    try:
                        # å°è¯•è¿æ¥æ•°æ®åº“æ£€æŸ¥å¥åº·çŠ¶æ€
                        conn = sqlite3.connect(db_path)
                        cursor = conn.cursor()
                        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                        tables = cursor.fetchall()
                        conn.close()
                        
                        db_status["databases"].append({
                            "name": db_file,
                            "size_mb": file_size,
                            "table_count": len(tables),
                            "status": "healthy"
                        })
                        
                    except Exception as e:
                        db_status["databases"].append({
                            "name": db_file,
                            "size_mb": file_size,
                            "status": "error",
                            "error": str(e)
                        })
                    
                    db_status["total_size_mb"] += file_size
                else:
                    db_status["databases"].append({
                        "name": db_file,
                        "status": "missing"
                    })
            
            # åˆ¤æ–­æ•´ä½“å¥åº·çŠ¶æ€
            healthy_dbs = sum(1 for db in db_status["databases"] if db.get("status") == "healthy")
            total_dbs = len([db for db in db_status["databases"] if db.get("status") != "missing"])
            
            if total_dbs == 0:
                db_status["health_status"] = "no_databases"
            elif healthy_dbs == total_dbs:
                db_status["health_status"] = "excellent"
            elif healthy_dbs >= total_dbs * 0.8:
                db_status["health_status"] = "good"
            else:
                db_status["health_status"] = "needs_attention"
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")
        
        return db_status
    
    def check_data_freshness(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®æ–°é²œåº¦"""
        freshness_status = {
            "data_files": [],
            "oldest_file_hours": 0,
            "newest_file_hours": 0,
            "freshness_score": 0
        }
        
        try:
            current_time = datetime.now()
            
            if os.path.exists(self.local_data_dir):
                for file_name in os.listdir(self.local_data_dir):
                    if file_name.endswith('.json') and not file_name.startswith('.'):
                        file_path = os.path.join(self.local_data_dir, file_name)
                        
                        try:
                            file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                            hours_old = (current_time - file_mtime).total_seconds() / 3600
                            
                            # å°è¯•è¯»å–æ–‡ä»¶è·å–è®°å½•æ•°
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            
                            record_count = len(data.get("data", []))
                            
                            freshness_status["data_files"].append({
                                "file_name": file_name,
                                "hours_old": hours_old,
                                "record_count": record_count,
                                "last_modified": file_mtime.isoformat(),
                                "freshness": "fresh" if hours_old < 24 else 
                                           "stale" if hours_old < 72 else "very_stale"
                            })
                            
                        except Exception as e:
                            logger.warning(f"å¤„ç†æ–‡ä»¶ {file_name} å¤±è´¥: {e}")
                
                if freshness_status["data_files"]:
                    hours_list = [f["hours_old"] for f in freshness_status["data_files"]]
                    freshness_status["oldest_file_hours"] = max(hours_list)
                    freshness_status["newest_file_hours"] = min(hours_list)
                    
                    # è®¡ç®—æ–°é²œåº¦åˆ†æ•° (0-100)
                    fresh_files = sum(1 for f in freshness_status["data_files"] if f["freshness"] == "fresh")
                    total_files = len(freshness_status["data_files"])
                    freshness_status["freshness_score"] = (fresh_files / total_files) * 100 if total_files > 0 else 0
                    
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ•°æ®æ–°é²œåº¦å¤±è´¥: {e}")
        
        return freshness_status
    
    def check_monitoring_alerts(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç›‘æ§å‘Šè­¦"""
        alert_status = {
            "active_alerts": [],
            "resolved_alerts": [],
            "alert_summary": {}
        }
        
        try:
            monitoring_db_path = os.path.join(self.local_data_dir, "monitoring.db")
            
            if os.path.exists(monitoring_db_path):
                conn = sqlite3.connect(monitoring_db_path)
                cursor = conn.cursor()
                
                # è·å–æ´»è·ƒå‘Šè­¦
                cursor.execute('''
                    SELECT alert_type, severity, message, alert_time
                    FROM alerts 
                    WHERE resolved = 0 
                    ORDER BY alert_time DESC
                ''')
                
                active_alerts = cursor.fetchall()
                alert_status["active_alerts"] = [
                    {
                        "type": alert[0],
                        "severity": alert[1], 
                        "message": alert[2],
                        "time": alert[3]
                    }
                    for alert in active_alerts
                ]
                
                # è·å–æœ€è¿‘24å°æ—¶å·²è§£å†³çš„å‘Šè­¦
                yesterday = (datetime.now() - timedelta(days=1)).isoformat()
                cursor.execute('''
                    SELECT alert_type, severity, message, alert_time, resolved_time
                    FROM alerts 
                    WHERE resolved = 1 AND alert_time > ?
                    ORDER BY resolved_time DESC
                    LIMIT 10
                ''', (yesterday,))
                
                resolved_alerts = cursor.fetchall()
                alert_status["resolved_alerts"] = [
                    {
                        "type": alert[0],
                        "severity": alert[1],
                        "message": alert[2],
                        "alert_time": alert[3],
                        "resolved_time": alert[4]
                    }
                    for alert in resolved_alerts
                ]
                
                # å‘Šè­¦ç»Ÿè®¡
                cursor.execute('''
                    SELECT 
                        COUNT(*) as total_alerts,
                        SUM(CASE WHEN resolved = 0 THEN 1 ELSE 0 END) as active_count,
                        SUM(CASE WHEN severity = 'critical' AND resolved = 0 THEN 1 ELSE 0 END) as critical_count
                    FROM alerts
                ''')
                
                summary = cursor.fetchone()
                if summary:
                    alert_status["alert_summary"] = {
                        "total_alerts": summary[0],
                        "active_alerts": summary[1],
                        "critical_alerts": summary[2]
                    }
                
                conn.close()
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç›‘æ§å‘Šè­¦å¤±è´¥: {e}")
        
        return alert_status
    
    def generate_status_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆç³»ç»ŸçŠ¶æ€æ€»ç»“"""
        logger.info("å¼€å§‹ç”Ÿæˆç³»ç»ŸçŠ¶æ€æ€»ç»“")
        
        # æ”¶é›†å„é¡¹çŠ¶æ€
        process_status = self.check_running_processes()
        db_status = self.check_database_status()
        freshness_status = self.check_data_freshness()
        alert_status = self.check_monitoring_alerts()
        
        # è®¡ç®—æ•´ä½“å¥åº·åˆ†æ•°
        health_score = 0
        max_score = 100
        
        # è¿›ç¨‹çŠ¶æ€è¯„åˆ† (25åˆ†)
        if len(process_status["system_processes"]) >= 2:
            health_score += 25
        elif len(process_status["system_processes"]) >= 1:
            health_score += 15
        
        # æ•°æ®åº“çŠ¶æ€è¯„åˆ† (25åˆ†)
        if db_status["health_status"] == "excellent":
            health_score += 25
        elif db_status["health_status"] == "good":
            health_score += 20
        elif db_status["health_status"] == "needs_attention":
            health_score += 10
        
        # æ•°æ®æ–°é²œåº¦è¯„åˆ† (25åˆ†)
        health_score += min(25, freshness_status["freshness_score"] * 0.25)
        
        # å‘Šè­¦çŠ¶æ€è¯„åˆ† (25åˆ†)
        critical_alerts = alert_status["alert_summary"].get("critical_alerts", 0)
        active_alerts = alert_status["alert_summary"].get("active_alerts", 0)
        
        if critical_alerts == 0 and active_alerts == 0:
            health_score += 25
        elif critical_alerts == 0 and active_alerts <= 2:
            health_score += 20
        elif critical_alerts <= 1:
            health_score += 10
        
        # ç¡®å®šæ•´ä½“çŠ¶æ€
        if health_score >= 90:
            overall_status = "excellent"
        elif health_score >= 75:
            overall_status = "good"
        elif health_score >= 60:
            overall_status = "acceptable"
        else:
            overall_status = "needs_attention"
        
        # æ„å»ºçŠ¶æ€æ€»ç»“
        status_summary = {
            "summary_metadata": {
                "generation_time": datetime.now().isoformat(),
                "health_score": health_score,
                "overall_status": overall_status
            },
            "system_processes": process_status,
            "database_status": db_status,
            "data_freshness": freshness_status,
            "monitoring_alerts": alert_status,
            "recommendations": self.generate_recommendations(
                process_status, db_status, freshness_status, alert_status
            )
        }
        
        return status_summary
    
    def generate_recommendations(self, process_status: Dict, db_status: Dict, 
                               freshness_status: Dict, alert_status: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # è¿›ç¨‹ç›¸å…³å»ºè®®
        if len(process_status["system_processes"]) == 0:
            recommendations.append("ğŸš¨ æ²¡æœ‰æ£€æµ‹åˆ°è¿è¡Œä¸­çš„ç³»ç»Ÿè¿›ç¨‹ï¼Œå»ºè®®å¯åŠ¨ç›‘æ§å’ŒåŒæ­¥ç³»ç»Ÿ")
        elif len(process_status["system_processes"]) < 2:
            recommendations.append("âš ï¸ ç³»ç»Ÿè¿›ç¨‹æ•°é‡è¾ƒå°‘ï¼Œå»ºè®®æ£€æŸ¥æ‰€æœ‰è‡ªåŠ¨åŒ–ç³»ç»Ÿæ˜¯å¦æ­£å¸¸è¿è¡Œ")
        
        # èµ„æºä½¿ç”¨å»ºè®®
        if process_status["resource_usage"]["cpu_percent"] > 80:
            recommendations.append("ğŸ”¥ CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½")
        
        if process_status["resource_usage"]["memory_percent"] > 85:
            recommendations.append("ğŸ’¾ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®é‡Šæ”¾å†…å­˜æˆ–å¢åŠ ç³»ç»Ÿèµ„æº")
        
        if process_status["resource_usage"]["disk_free_gb"] < 5:
            recommendations.append("ğŸ’¿ ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå»ºè®®æ¸…ç†ä¸´æ—¶æ–‡ä»¶æˆ–æ‰©å±•å­˜å‚¨")
        
        # æ•°æ®åº“ç›¸å…³å»ºè®®
        if db_status["health_status"] == "needs_attention":
            recommendations.append("ğŸ—„ï¸ æ•°æ®åº“çŠ¶æ€éœ€è¦å…³æ³¨ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§")
        elif db_status["health_status"] == "no_databases":
            recommendations.append("âŒ æœªå‘ç°æ•°æ®åº“æ–‡ä»¶ï¼Œå»ºè®®é‡æ–°åˆå§‹åŒ–ç³»ç»Ÿ")
        
        # æ•°æ®æ–°é²œåº¦å»ºè®®
        if freshness_status["freshness_score"] < 50:
            recommendations.append("ğŸ“… æ•°æ®æ–°é²œåº¦è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®åŒæ­¥æœºåˆ¶")
        
        if freshness_status["oldest_file_hours"] > 72:
            recommendations.append("â° å‘ç°è¿‡æœŸæ•°æ®æ–‡ä»¶ï¼Œå»ºè®®æ›´æ–°æ•°æ®æˆ–æ¸…ç†æ—§æ–‡ä»¶")
        
        # å‘Šè­¦ç›¸å…³å»ºè®®
        critical_alerts = alert_status["alert_summary"].get("critical_alerts", 0)
        if critical_alerts > 0:
            recommendations.append(f"ğŸš¨ å‘ç°{critical_alerts}ä¸ªä¸¥é‡å‘Šè­¦ï¼Œéœ€è¦ç«‹å³å¤„ç†")
        
        active_alerts = alert_status["alert_summary"].get("active_alerts", 0)
        if active_alerts > 5:
            recommendations.append(f"âš ï¸ æ´»è·ƒå‘Šè­¦æ•°é‡è¾ƒå¤š({active_alerts}ä¸ª)ï¼Œå»ºè®®æ‰¹é‡å¤„ç†")
        
        # é€šç”¨å»ºè®®
        if not recommendations:
            recommendations.append("âœ… ç³»ç»Ÿè¿è¡ŒçŠ¶æ€è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå®šæœŸç›‘æ§")
        
        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    checker = SystemStatusChecker()
    
    print("=" * 80)
    print("PC28ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å™¨")
    print("=" * 80)
    
    # ç”ŸæˆçŠ¶æ€æ€»ç»“
    status_summary = checker.generate_status_summary()
    
    # æ˜¾ç¤ºæ€»ä½“çŠ¶æ€
    metadata = status_summary["summary_metadata"]
    print(f"æ£€æŸ¥æ—¶é—´: {metadata['generation_time']}")
    print(f"å¥åº·åˆ†æ•°: {metadata['health_score']}/100")
    print(f"æ•´ä½“çŠ¶æ€: {metadata['overall_status']}")
    
    # æ˜¾ç¤ºè¿è¡Œè¿›ç¨‹
    processes = status_summary["system_processes"]
    print(f"\nğŸ”„ è¿è¡Œä¸­çš„ç³»ç»Ÿè¿›ç¨‹: {len(processes['system_processes'])}")
    for proc in processes["system_processes"]:
        print(f"  âœ“ {proc['script']} (PID: {proc['pid']}, CPU: {proc['cpu_percent']:.1f}%)")
    
    # æ˜¾ç¤ºèµ„æºä½¿ç”¨
    resources = processes["resource_usage"]
    print(f"\nğŸ’» ç³»ç»Ÿèµ„æºä½¿ç”¨:")
    print(f"  CPU: {resources['cpu_percent']:.1f}%")
    print(f"  å†…å­˜: {resources['memory_percent']:.1f}%")
    print(f"  ç£ç›˜: {resources['disk_usage_percent']:.1f}% (å‰©ä½™: {resources['disk_free_gb']:.1f}GB)")
    
    # æ˜¾ç¤ºæ•°æ®åº“çŠ¶æ€
    db_status = status_summary["database_status"]
    print(f"\nğŸ—„ï¸ æ•°æ®åº“çŠ¶æ€: {db_status['health_status']} (æ€»å¤§å°: {db_status['total_size_mb']:.1f}MB)")
    healthy_dbs = sum(1 for db in db_status["databases"] if db.get("status") == "healthy")
    print(f"  å¥åº·æ•°æ®åº“: {healthy_dbs}/{len(db_status['databases'])}")
    
    # æ˜¾ç¤ºæ•°æ®æ–°é²œåº¦
    freshness = status_summary["data_freshness"]
    print(f"\nğŸ“… æ•°æ®æ–°é²œåº¦: {freshness['freshness_score']:.1f}%")
    if freshness["data_files"]:
        fresh_files = sum(1 for f in freshness["data_files"] if f["freshness"] == "fresh")
        print(f"  æ–°é²œæ–‡ä»¶: {fresh_files}/{len(freshness['data_files'])}")
    
    # æ˜¾ç¤ºå‘Šè­¦çŠ¶æ€
    alerts = status_summary["monitoring_alerts"]
    alert_summary = alerts["alert_summary"]
    if alert_summary:
        print(f"\nğŸš¨ ç›‘æ§å‘Šè­¦:")
        print(f"  æ´»è·ƒå‘Šè­¦: {alert_summary.get('active_alerts', 0)}")
        print(f"  ä¸¥é‡å‘Šè­¦: {alert_summary.get('critical_alerts', 0)}")
    
    # æ˜¾ç¤ºå»ºè®®
    recommendations = status_summary["recommendations"]
    if recommendations:
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for rec in recommendations[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªå»ºè®®
            print(f"  {rec}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = f"/Users/a606/cloud_function_source/reports/system_status_{timestamp}.json"
        
        os.makedirs(os.path.dirname(report_path), exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(status_summary, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
    except Exception as e:
        logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
    
    print("=" * 80)
    print("çŠ¶æ€æ£€æŸ¥å®Œæˆ")
    print("=" * 80)
    
    return status_summary

if __name__ == "__main__":
    main()