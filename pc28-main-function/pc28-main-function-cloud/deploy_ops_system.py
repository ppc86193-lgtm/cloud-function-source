#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PC28è¿ç»´ç®¡ç†ç³»ç»Ÿéƒ¨ç½²è„šæœ¬
ç”¨äºåœ¨Google Cloud Platformä¸Šéƒ¨ç½²å®Œæ•´çš„è¿ç»´ç®¡ç†ç³»ç»Ÿ
"""

import os
import sys
import json
import time
import logging
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

class PC28OpsDeployer:
    """PC28è¿ç»´ç³»ç»Ÿéƒ¨ç½²å™¨"""
    
    def __init__(self, project_id: str = None, region: str = 'us-central1'):
        self.project_id = project_id or 'pc28-data-platform'
        self.region = region
        self.deployment_dir = os.path.dirname(__file__)
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # éƒ¨ç½²é…ç½®
        self.deployment_config = {
            'cloud_functions': [
                {
                    'name': 'pc28-ops-monitor',
                    'source': 'monitoring_dashboard.py',
                    'entry_point': 'monitor_handler',
                    'runtime': 'python39',
                    'memory': '512MB',
                    'timeout': '300s',
                    'trigger': 'http'
                },
                {
                    'name': 'pc28-data-quality',
                    'source': 'data_quality_checker.py',
                    'entry_point': 'quality_check_handler',
                    'runtime': 'python39',
                    'memory': '1GB',
                    'timeout': '540s',
                    'trigger': 'pubsub',
                    'topic': 'pc28-quality-check'
                },
                {
                    'name': 'pc28-alert-system',
                    'source': 'alert_notification_system.py',
                    'entry_point': 'alert_handler',
                    'runtime': 'python39',
                    'memory': '256MB',
                    'timeout': '60s',
                    'trigger': 'pubsub',
                    'topic': 'pc28-alerts'
                }
            ],
            'cloud_scheduler': [
                {
                    'name': 'pc28-health-check',
                    'schedule': '*/15 * * * *',
                    'target_function': 'pc28-ops-monitor',
                    'payload': {'action': 'health_check'}
                },
                {
                    'name': 'pc28-quality-check',
                    'schedule': '0 */2 * * *',
                    'target_topic': 'pc28-quality-check',
                    'payload': {'action': 'full_check'}
                },
                {
                    'name': 'pc28-component-update',
                    'schedule': '0 6 * * *',
                    'target_function': 'pc28-ops-monitor',
                    'payload': {'action': 'check_updates'}
                }
            ],
            'pubsub_topics': [
                'pc28-quality-check',
                'pc28-alerts',
                'pc28-system-events'
            ],
            'cloud_storage': {
                'buckets': [
                    {
                        'name': f'{self.project_id}-ops-logs',
                        'location': self.region,
                        'storage_class': 'STANDARD'
                    },
                    {
                        'name': f'{self.project_id}-ops-backups',
                        'location': self.region,
                        'storage_class': 'NEARLINE'
                    }
                ]
            },
            'cloud_monitoring': {
                'dashboards': [
                    {
                        'name': 'PC28-Operations-Dashboard',
                        'config_file': 'monitoring_dashboard_config.json'
                    }
                ],
                'alert_policies': [
                    {
                        'name': 'PC28-High-Error-Rate',
                        'condition': 'error_rate > 5%',
                        'notification_channels': ['email', 'slack']
                    },
                    {
                        'name': 'PC28-Low-Data-Quality',
                        'condition': 'data_quality_score < 80',
                        'notification_channels': ['email']
                    }
                ]
            }
        }
        
        self.logger.info(f"PC28è¿ç»´ç³»ç»Ÿéƒ¨ç½²å™¨åˆå§‹åŒ–å®Œæˆ - é¡¹ç›®: {self.project_id}, åŒºåŸŸ: {self.region}")
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_dir = os.path.join(self.deployment_dir, 'logs')
        os.makedirs(log_dir, exist_ok=True)
        
        log_file = os.path.join(log_dir, f'deployment_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        self.logger = logging.getLogger(__name__)
    
    def run_command(self, command: str, check: bool = True) -> subprocess.CompletedProcess:
        """æ‰§è¡Œå‘½ä»¤"""
        self.logger.info(f"æ‰§è¡Œå‘½ä»¤: {command}")
        
        try:
            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                check=check
            )
            
            if result.stdout:
                self.logger.info(f"è¾“å‡º: {result.stdout.strip()}")
            
            if result.stderr and result.returncode != 0:
                self.logger.error(f"é”™è¯¯: {result.stderr.strip()}")
            
            return result
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            if e.stdout:
                self.logger.error(f"æ ‡å‡†è¾“å‡º: {e.stdout}")
            if e.stderr:
                self.logger.error(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            raise
    
    def check_prerequisites(self) -> bool:
        """æ£€æŸ¥éƒ¨ç½²å‰ææ¡ä»¶"""
        self.logger.info("æ£€æŸ¥éƒ¨ç½²å‰ææ¡ä»¶...")
        
        # æ£€æŸ¥gcloud CLI
        try:
            result = self.run_command('gcloud version', check=False)
            if result.returncode != 0:
                self.logger.error("gcloud CLIæœªå®‰è£…æˆ–é…ç½®ä¸æ­£ç¡®")
                return False
            self.logger.info("âœ… gcloud CLIå·²å®‰è£…")
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥gcloud CLIå¤±è´¥: {e}")
            return False
        
        # æ£€æŸ¥é¡¹ç›®è®¿é—®æƒé™
        try:
            result = self.run_command(f'gcloud config set project {self.project_id}')
            self.logger.info(f"âœ… é¡¹ç›® {self.project_id} è®¿é—®æ­£å¸¸")
        except Exception as e:
            self.logger.error(f"æ— æ³•è®¿é—®é¡¹ç›® {self.project_id}: {e}")
            return False
        
        # æ£€æŸ¥å¿…è¦çš„APIæ˜¯å¦å¯ç”¨
        required_apis = [
            'cloudfunctions.googleapis.com',
            'cloudscheduler.googleapis.com',
            'pubsub.googleapis.com',
            'storage.googleapis.com',
            'monitoring.googleapis.com',
            'bigquery.googleapis.com'
        ]
        
        for api in required_apis:
            try:
                result = self.run_command(f'gcloud services list --enabled --filter="name:{api}" --format="value(name)"')
                if api not in result.stdout:
                    self.logger.warning(f"API {api} æœªå¯ç”¨ï¼Œæ­£åœ¨å¯ç”¨...")
                    self.run_command(f'gcloud services enable {api}')
                    time.sleep(5)  # ç­‰å¾…APIå¯ç”¨
                self.logger.info(f"âœ… API {api} å·²å¯ç”¨")
            except Exception as e:
                self.logger.error(f"æ£€æŸ¥/å¯ç”¨API {api} å¤±è´¥: {e}")
                return False
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        required_files = [
            'ops_manager_main.py',
            'monitoring_dashboard.py',
            'data_quality_checker.py',
            'alert_notification_system.py',
            'concurrency_tuner.py',
            'component_updater.py',
            'config/ops_config.json'
        ]
        
        for file_path in required_files:
            full_path = os.path.join(self.deployment_dir, file_path)
            if not os.path.exists(full_path):
                self.logger.error(f"å¿…è¦æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
            self.logger.info(f"âœ… æ–‡ä»¶å­˜åœ¨: {file_path}")
        
        self.logger.info("âœ… æ‰€æœ‰å‰ææ¡ä»¶æ£€æŸ¥é€šè¿‡")
        return True
    
    def create_requirements_txt(self):
        """åˆ›å»ºrequirements.txtæ–‡ä»¶"""
        requirements = [
            'google-cloud-bigquery>=3.4.0',
            'google-cloud-storage>=2.7.0',
            'google-cloud-monitoring>=2.11.1',
            'google-cloud-pubsub>=2.15.1',
            'google-cloud-functions>=1.8.1',
            'requests>=2.28.0',
            'pandas>=1.5.0',
            'numpy>=1.21.0',
            'psutil>=5.9.0',
            'schedule>=1.2.0',
            'slack-sdk>=3.19.0',
            'functions-framework>=3.2.0'
        ]
        
        requirements_file = os.path.join(self.deployment_dir, 'requirements.txt')
        with open(requirements_file, 'w') as f:
            f.write('\n'.join(requirements))
        
        self.logger.info(f"âœ… åˆ›å»ºrequirements.txt: {requirements_file}")
    
    def deploy_pubsub_topics(self):
        """éƒ¨ç½²Pub/Subä¸»é¢˜"""
        self.logger.info("éƒ¨ç½²Pub/Subä¸»é¢˜...")
        
        for topic in self.deployment_config['pubsub_topics']:
            try:
                # æ£€æŸ¥ä¸»é¢˜æ˜¯å¦å­˜åœ¨
                result = self.run_command(
                    f'gcloud pubsub topics describe {topic} --project={self.project_id}',
                    check=False
                )
                
                if result.returncode != 0:
                    # åˆ›å»ºä¸»é¢˜
                    self.run_command(f'gcloud pubsub topics create {topic} --project={self.project_id}')
                    self.logger.info(f"âœ… åˆ›å»ºPub/Subä¸»é¢˜: {topic}")
                else:
                    self.logger.info(f"âœ… Pub/Subä¸»é¢˜å·²å­˜åœ¨: {topic}")
                    
            except Exception as e:
                self.logger.error(f"éƒ¨ç½²Pub/Subä¸»é¢˜ {topic} å¤±è´¥: {e}")
                raise
    
    def deploy_cloud_storage(self):
        """éƒ¨ç½²Cloud Storageå­˜å‚¨æ¡¶"""
        self.logger.info("éƒ¨ç½²Cloud Storageå­˜å‚¨æ¡¶...")
        
        for bucket_config in self.deployment_config['cloud_storage']['buckets']:
            bucket_name = bucket_config['name']
            
            try:
                # æ£€æŸ¥å­˜å‚¨æ¡¶æ˜¯å¦å­˜åœ¨
                result = self.run_command(
                    f'gsutil ls -b gs://{bucket_name}',
                    check=False
                )
                
                if result.returncode != 0:
                    # åˆ›å»ºå­˜å‚¨æ¡¶
                    location = bucket_config.get('location', self.region)
                    storage_class = bucket_config.get('storage_class', 'STANDARD')
                    
                    self.run_command(
                        f'gsutil mb -p {self.project_id} -c {storage_class} -l {location} gs://{bucket_name}'
                    )
                    self.logger.info(f"âœ… åˆ›å»ºå­˜å‚¨æ¡¶: {bucket_name}")
                else:
                    self.logger.info(f"âœ… å­˜å‚¨æ¡¶å·²å­˜åœ¨: {bucket_name}")
                    
            except Exception as e:
                self.logger.error(f"éƒ¨ç½²å­˜å‚¨æ¡¶ {bucket_name} å¤±è´¥: {e}")
                raise
    
    def create_cloud_function_handler(self, function_config: Dict[str, Any]):
        """ä¸ºCloud Functionåˆ›å»ºå¤„ç†å‡½æ•°"""
        function_name = function_config['name']
        source_file = function_config['source']
        entry_point = function_config['entry_point']
        
        # åˆ›å»ºmain.pyæ–‡ä»¶
        main_py_content = f"""
import json
import logging
from typing import Any, Dict

# å¯¼å…¥æºæ¨¡å—
try:
    from {source_file.replace('.py', '')} import *
except ImportError as e:
    logging.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {{e}}")
    raise

def {entry_point}(request=None, context=None):
    \"\"\"Cloud Functionå…¥å£ç‚¹\"\"\"
    try:
        # è§£æè¯·æ±‚æ•°æ®
        if hasattr(request, 'get_json'):
            data = request.get_json() or {{}}
        elif hasattr(request, 'data'):
            data = json.loads(request.data.decode('utf-8')) if request.data else {{}}
        else:
            data = {{}}
        
        logging.info(f"å¤„ç†è¯·æ±‚: {{data}}")
        
        # æ ¹æ®ä¸åŒçš„å‡½æ•°æ‰§è¡Œç›¸åº”é€»è¾‘
        if '{function_name}' == 'pc28-ops-monitor':
            return handle_monitoring_request(data)
        elif '{function_name}' == 'pc28-data-quality':
            return handle_quality_check_request(data)
        elif '{function_name}' == 'pc28-alert-system':
            return handle_alert_request(data)
        else:
            return {{'error': 'Unknown function'}}
            
    except Exception as e:
        logging.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {{e}}")
        return {{'error': str(e)}}

def handle_monitoring_request(data: Dict[str, Any]):
    \"\"\"å¤„ç†ç›‘æ§è¯·æ±‚\"\"\"
    action = data.get('action', 'health_check')
    
    if action == 'health_check':
        dashboard = MonitoringDashboard()
        health = dashboard.get_system_health()
        return {{'status': 'success', 'data': health}}
    elif action == 'check_updates':
        updater = ComponentUpdater()
        updates = updater.check_updates()
        return {{'status': 'success', 'data': updates}}
    else:
        return {{'error': f'Unknown action: {{action}}'}}

def handle_quality_check_request(data: Dict[str, Any]):
    \"\"\"å¤„ç†æ•°æ®è´¨é‡æ£€æŸ¥è¯·æ±‚\"\"\"
    action = data.get('action', 'full_check')
    
    if action == 'full_check':
        checker = DataQualityChecker()
        issues = checker.check_all_tables()
        return {{'status': 'success', 'issues_count': len(issues), 'issues': issues}}
    else:
        return {{'error': f'Unknown action: {{action}}'}}

def handle_alert_request(data: Dict[str, Any]):
    \"\"\"å¤„ç†å‘Šè­¦è¯·æ±‚\"\"\"
    alert_system = AlertNotificationSystem()
    
    alert_type = data.get('type', 'system')
    level = data.get('level', 'medium')
    title = data.get('title', 'ç³»ç»Ÿå‘Šè­¦')
    message = data.get('message', 'æ£€æµ‹åˆ°ç³»ç»Ÿå¼‚å¸¸')
    source = data.get('source', 'cloud_function')
    
    alert_system.create_alert(
        alert_type=alert_type,
        level=level,
        title=title,
        message=message,
        source=source,
        metadata=data.get('metadata', {{}})
    )
    
    return {{'status': 'success', 'message': 'Alert sent'}}
"""
        
        # åˆ›å»ºå‡½æ•°ç›®å½•
        function_dir = os.path.join(self.deployment_dir, 'functions', function_name)
        os.makedirs(function_dir, exist_ok=True)
        
        # å†™å…¥main.py
        with open(os.path.join(function_dir, 'main.py'), 'w', encoding='utf-8') as f:
            f.write(main_py_content)
        
        # å¤åˆ¶æºæ–‡ä»¶
        source_path = os.path.join(self.deployment_dir, source_file)
        if os.path.exists(source_path):
            import shutil
            shutil.copy2(source_path, function_dir)
        
        # å¤åˆ¶requirements.txt
        requirements_path = os.path.join(self.deployment_dir, 'requirements.txt')
        if os.path.exists(requirements_path):
            import shutil
            shutil.copy2(requirements_path, function_dir)
        
        # å¤åˆ¶é…ç½®æ–‡ä»¶
        config_dir = os.path.join(self.deployment_dir, 'config')
        if os.path.exists(config_dir):
            import shutil
            shutil.copytree(config_dir, os.path.join(function_dir, 'config'), dirs_exist_ok=True)
        
        self.logger.info(f"âœ… åˆ›å»ºCloud Functionå¤„ç†å‡½æ•°: {function_name}")
        return function_dir
    
    def deploy_cloud_functions(self):
        """éƒ¨ç½²Cloud Functions"""
        self.logger.info("éƒ¨ç½²Cloud Functions...")
        
        for function_config in self.deployment_config['cloud_functions']:
            function_name = function_config['name']
            
            try:
                # åˆ›å»ºå‡½æ•°å¤„ç†ä»£ç 
                function_dir = self.create_cloud_function_handler(function_config)
                
                # æ„å»ºéƒ¨ç½²å‘½ä»¤
                deploy_cmd = [
                    'gcloud', 'functions', 'deploy', function_name,
                    f'--source={function_dir}',
                    f'--entry-point={function_config["entry_point"]}',
                    f'--runtime={function_config["runtime"]}',
                    f'--memory={function_config["memory"]}',
                    f'--timeout={function_config["timeout"]}',
                    f'--region={self.region}',
                    f'--project={self.project_id}'
                ]
                
                # æ·»åŠ è§¦å‘å™¨
                if function_config['trigger'] == 'http':
                    deploy_cmd.extend(['--trigger-http', '--allow-unauthenticated'])
                elif function_config['trigger'] == 'pubsub':
                    deploy_cmd.extend([f'--trigger-topic={function_config["topic"]}'])
                
                # æ‰§è¡Œéƒ¨ç½²
                self.run_command(' '.join(deploy_cmd))
                self.logger.info(f"âœ… éƒ¨ç½²Cloud Function: {function_name}")
                
            except Exception as e:
                self.logger.error(f"éƒ¨ç½²Cloud Function {function_name} å¤±è´¥: {e}")
                raise
    
    def deploy_cloud_scheduler(self):
        """éƒ¨ç½²Cloud Schedulerä»»åŠ¡"""
        self.logger.info("éƒ¨ç½²Cloud Schedulerä»»åŠ¡...")
        
        for job_config in self.deployment_config['cloud_scheduler']:
            job_name = job_config['name']
            
            try:
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
                result = self.run_command(
                    f'gcloud scheduler jobs describe {job_name} --location={self.region} --project={self.project_id}',
                    check=False
                )
                
                if result.returncode == 0:
                    # åˆ é™¤ç°æœ‰ä»»åŠ¡
                    self.run_command(
                        f'gcloud scheduler jobs delete {job_name} --location={self.region} --project={self.project_id} --quiet'
                    )
                
                # åˆ›å»ºæ–°ä»»åŠ¡
                if 'target_function' in job_config:
                    # HTTPè§¦å‘å™¨
                    function_url = f'https://{self.region}-{self.project_id}.cloudfunctions.net/{job_config["target_function"]}'
                    payload = json.dumps(job_config['payload'])
                    
                    self.run_command(
                        f'gcloud scheduler jobs create http {job_name} '
                        f'--schedule="{job_config["schedule"]}" '
                        f'--uri="{function_url}" '
                        f'--http-method=POST '
                        f'--headers="Content-Type=application/json" '
                        f'--message-body=\'{payload}\' '
                        f'--location={self.region} '
                        f'--project={self.project_id}'
                    )
                elif 'target_topic' in job_config:
                    # Pub/Subè§¦å‘å™¨
                    payload = json.dumps(job_config['payload'])
                    
                    self.run_command(
                        f'gcloud scheduler jobs create pubsub {job_name} '
                        f'--schedule="{job_config["schedule"]}" '
                        f'--topic={job_config["target_topic"]} '
                        f'--message-body=\'{payload}\' '
                        f'--location={self.region} '
                        f'--project={self.project_id}'
                    )
                
                self.logger.info(f"âœ… éƒ¨ç½²Schedulerä»»åŠ¡: {job_name}")
                
            except Exception as e:
                self.logger.error(f"éƒ¨ç½²Schedulerä»»åŠ¡ {job_name} å¤±è´¥: {e}")
                raise
    
    def deploy_monitoring_dashboard(self):
        """éƒ¨ç½²ç›‘æ§ä»ªè¡¨æ¿"""
        self.logger.info("éƒ¨ç½²ç›‘æ§ä»ªè¡¨æ¿...")
        
        # åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿é…ç½®
        dashboard_config = {
            "displayName": "PC28 Operations Dashboard",
            "mosaicLayout": {
                "tiles": [
                    {
                        "width": 6,
                        "height": 4,
                        "widget": {
                            "title": "System Health Score",
                            "scorecard": {
                                "timeSeriesQuery": {
                                    "timeSeriesFilter": {
                                        "filter": 'resource.type="cloud_function"',
                                        "aggregation": {
                                            "alignmentPeriod": "60s",
                                            "perSeriesAligner": "ALIGN_MEAN"
                                        }
                                    }
                                }
                            }
                        }
                    },
                    {
                        "width": 6,
                        "height": 4,
                        "xPos": 6,
                        "widget": {
                            "title": "Error Rate",
                            "xyChart": {
                                "dataSets": [{
                                    "timeSeriesQuery": {
                                        "timeSeriesFilter": {
                                            "filter": 'resource.type="cloud_function"',
                                            "aggregation": {
                                                "alignmentPeriod": "60s",
                                                "perSeriesAligner": "ALIGN_RATE"
                                            }
                                        }
                                    }
                                }]
                            }
                        }
                    }
                ]
            }
        }
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_file = os.path.join(self.deployment_dir, 'monitoring_dashboard_config.json')
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(dashboard_config, f, ensure_ascii=False, indent=2)
        
        try:
            # åˆ›å»ºä»ªè¡¨æ¿
            self.run_command(
                f'gcloud monitoring dashboards create --config-from-file={config_file} --project={self.project_id}'
            )
            self.logger.info("âœ… éƒ¨ç½²ç›‘æ§ä»ªè¡¨æ¿")
            
        except Exception as e:
            self.logger.warning(f"éƒ¨ç½²ç›‘æ§ä»ªè¡¨æ¿å¤±è´¥: {e}")
    
    def verify_deployment(self) -> Dict[str, Any]:
        """éªŒè¯éƒ¨ç½²ç»“æœ"""
        self.logger.info("éªŒè¯éƒ¨ç½²ç»“æœ...")
        
        verification_results = {
            'timestamp': datetime.now().isoformat(),
            'overall_status': 'success',
            'components': {}
        }
        
        # éªŒè¯Cloud Functions
        try:
            result = self.run_command(
                f'gcloud functions list --regions={self.region} --project={self.project_id} --format="value(name)"'
            )
            deployed_functions = result.stdout.strip().split('\n') if result.stdout.strip() else []
            
            expected_functions = [f['name'] for f in self.deployment_config['cloud_functions']]
            
            verification_results['components']['cloud_functions'] = {
                'expected': len(expected_functions),
                'deployed': len([f for f in deployed_functions if any(ef in f for ef in expected_functions)]),
                'status': 'success' if all(any(ef in f for f in deployed_functions) for ef in expected_functions) else 'partial'
            }
            
        except Exception as e:
            verification_results['components']['cloud_functions'] = {
                'status': 'error',
                'error': str(e)
            }
        
        # éªŒè¯Pub/Subä¸»é¢˜
        try:
            result = self.run_command(
                f'gcloud pubsub topics list --project={self.project_id} --format="value(name)"'
            )
            deployed_topics = [t.split('/')[-1] for t in result.stdout.strip().split('\n')] if result.stdout.strip() else []
            
            expected_topics = self.deployment_config['pubsub_topics']
            
            verification_results['components']['pubsub_topics'] = {
                'expected': len(expected_topics),
                'deployed': len([t for t in deployed_topics if t in expected_topics]),
                'status': 'success' if all(t in deployed_topics for t in expected_topics) else 'partial'
            }
            
        except Exception as e:
            verification_results['components']['pubsub_topics'] = {
                'status': 'error',
                'error': str(e)
            }
        
        # éªŒè¯Cloud Schedulerä»»åŠ¡
        try:
            result = self.run_command(
                f'gcloud scheduler jobs list --location={self.region} --project={self.project_id} --format="value(name)"'
            )
            deployed_jobs = [j.split('/')[-1] for j in result.stdout.strip().split('\n')] if result.stdout.strip() else []
            
            expected_jobs = [j['name'] for j in self.deployment_config['cloud_scheduler']]
            
            verification_results['components']['cloud_scheduler'] = {
                'expected': len(expected_jobs),
                'deployed': len([j for j in deployed_jobs if j in expected_jobs]),
                'status': 'success' if all(j in deployed_jobs for j in expected_jobs) else 'partial'
            }
            
        except Exception as e:
            verification_results['components']['cloud_scheduler'] = {
                'status': 'error',
                'error': str(e)
            }
        
        # éªŒè¯å­˜å‚¨æ¡¶
        try:
            result = self.run_command('gsutil ls')
            deployed_buckets = [b.replace('gs://', '').rstrip('/') for b in result.stdout.strip().split('\n')] if result.stdout.strip() else []
            
            expected_buckets = [b['name'] for b in self.deployment_config['cloud_storage']['buckets']]
            
            verification_results['components']['cloud_storage'] = {
                'expected': len(expected_buckets),
                'deployed': len([b for b in deployed_buckets if b in expected_buckets]),
                'status': 'success' if all(b in deployed_buckets for b in expected_buckets) else 'partial'
            }
            
        except Exception as e:
            verification_results['components']['cloud_storage'] = {
                'status': 'error',
                'error': str(e)
            }
        
        # ç¡®å®šæ•´ä½“çŠ¶æ€
        component_statuses = [comp.get('status', 'error') for comp in verification_results['components'].values()]
        if all(status == 'success' for status in component_statuses):
            verification_results['overall_status'] = 'success'
        elif any(status == 'success' for status in component_statuses):
            verification_results['overall_status'] = 'partial'
        else:
            verification_results['overall_status'] = 'failed'
        
        self.logger.info(f"éƒ¨ç½²éªŒè¯å®Œæˆï¼Œæ•´ä½“çŠ¶æ€: {verification_results['overall_status']}")
        
        return verification_results
    
    def deploy_full_system(self) -> Dict[str, Any]:
        """éƒ¨ç½²å®Œæ•´ç³»ç»Ÿ"""
        self.logger.info("å¼€å§‹éƒ¨ç½²PC28è¿ç»´ç®¡ç†ç³»ç»Ÿ...")
        
        deployment_report = {
            'start_time': datetime.now().isoformat(),
            'project_id': self.project_id,
            'region': self.region,
            'steps': [],
            'status': 'in_progress'
        }
        
        try:
            # 1. æ£€æŸ¥å‰ææ¡ä»¶
            self.logger.info("æ­¥éª¤ 1/8: æ£€æŸ¥å‰ææ¡ä»¶")
            if not self.check_prerequisites():
                raise Exception("å‰ææ¡ä»¶æ£€æŸ¥å¤±è´¥")
            deployment_report['steps'].append({'step': 1, 'name': 'å‰ææ¡ä»¶æ£€æŸ¥', 'status': 'success'})
            
            # 2. åˆ›å»ºrequirements.txt
            self.logger.info("æ­¥éª¤ 2/8: åˆ›å»ºä¾èµ–æ–‡ä»¶")
            self.create_requirements_txt()
            deployment_report['steps'].append({'step': 2, 'name': 'åˆ›å»ºä¾èµ–æ–‡ä»¶', 'status': 'success'})
            
            # 3. éƒ¨ç½²Pub/Subä¸»é¢˜
            self.logger.info("æ­¥éª¤ 3/8: éƒ¨ç½²Pub/Subä¸»é¢˜")
            self.deploy_pubsub_topics()
            deployment_report['steps'].append({'step': 3, 'name': 'Pub/Subä¸»é¢˜éƒ¨ç½²', 'status': 'success'})
            
            # 4. éƒ¨ç½²Cloud Storage
            self.logger.info("æ­¥éª¤ 4/8: éƒ¨ç½²Cloud Storage")
            self.deploy_cloud_storage()
            deployment_report['steps'].append({'step': 4, 'name': 'Cloud Storageéƒ¨ç½²', 'status': 'success'})
            
            # 5. éƒ¨ç½²Cloud Functions
            self.logger.info("æ­¥éª¤ 5/8: éƒ¨ç½²Cloud Functions")
            self.deploy_cloud_functions()
            deployment_report['steps'].append({'step': 5, 'name': 'Cloud Functionséƒ¨ç½²', 'status': 'success'})
            
            # 6. éƒ¨ç½²Cloud Scheduler
            self.logger.info("æ­¥éª¤ 6/8: éƒ¨ç½²Cloud Scheduler")
            self.deploy_cloud_scheduler()
            deployment_report['steps'].append({'step': 6, 'name': 'Cloud Scheduleréƒ¨ç½²', 'status': 'success'})
            
            # 7. éƒ¨ç½²ç›‘æ§ä»ªè¡¨æ¿
            self.logger.info("æ­¥éª¤ 7/8: éƒ¨ç½²ç›‘æ§ä»ªè¡¨æ¿")
            self.deploy_monitoring_dashboard()
            deployment_report['steps'].append({'step': 7, 'name': 'ç›‘æ§ä»ªè¡¨æ¿éƒ¨ç½²', 'status': 'success'})
            
            # 8. éªŒè¯éƒ¨ç½²
            self.logger.info("æ­¥éª¤ 8/8: éªŒè¯éƒ¨ç½²ç»“æœ")
            verification_results = self.verify_deployment()
            deployment_report['verification'] = verification_results
            deployment_report['steps'].append({'step': 8, 'name': 'éƒ¨ç½²éªŒè¯', 'status': 'success'})
            
            deployment_report['status'] = 'success'
            deployment_report['end_time'] = datetime.now().isoformat()
            
            self.logger.info("âœ… PC28è¿ç»´ç®¡ç†ç³»ç»Ÿéƒ¨ç½²å®Œæˆ")
            
        except Exception as e:
            deployment_report['status'] = 'failed'
            deployment_report['error'] = str(e)
            deployment_report['end_time'] = datetime.now().isoformat()
            
            self.logger.error(f"âŒ éƒ¨ç½²å¤±è´¥: {e}")
            raise
        
        return deployment_report

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PC28è¿ç»´ç®¡ç†ç³»ç»Ÿéƒ¨ç½²å·¥å…·')
    parser.add_argument('--project-id', type=str, help='Google Cloudé¡¹ç›®ID')
    parser.add_argument('--region', type=str, default='us-central1', help='éƒ¨ç½²åŒºåŸŸ')
    parser.add_argument('--verify-only', action='store_true', help='ä»…éªŒè¯ç°æœ‰éƒ¨ç½²')
    
    args = parser.parse_args()
    
    try:
        deployer = PC28OpsDeployer(args.project_id, args.region)
        
        if args.verify_only:
            print("éªŒè¯ç°æœ‰éƒ¨ç½²...")
            results = deployer.verify_deployment()
            print(json.dumps(results, ensure_ascii=False, indent=2))
        else:
            print("å¼€å§‹å®Œæ•´ç³»ç»Ÿéƒ¨ç½²...")
            report = deployer.deploy_full_system()
            
            # ä¿å­˜éƒ¨ç½²æŠ¥å‘Š
            report_file = os.path.join(
                os.path.dirname(__file__),
                'logs',
                f'deployment_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            )
            
            os.makedirs(os.path.dirname(report_file), exist_ok=True)
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"\néƒ¨ç½²æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            print(f"éƒ¨ç½²çŠ¶æ€: {report['status']}")
            
            if report['status'] == 'success':
                print("\nğŸ‰ PC28è¿ç»´ç®¡ç†ç³»ç»Ÿéƒ¨ç½²æˆåŠŸï¼")
                print("\nä¸‹ä¸€æ­¥æ“ä½œ:")
                print("1. é…ç½®å‘Šè­¦é€šçŸ¥æ¸ é“ (config/ops_config.json)")
                print("2. è¿è¡Œå¥åº·æ£€æŸ¥: python ops_manager_main.py health")
                print("3. å¯åŠ¨ç›‘æ§æœåŠ¡: python ops_manager_main.py start")
            else:
                print(f"\nâŒ éƒ¨ç½²å¤±è´¥: {report.get('error', 'æœªçŸ¥é”™è¯¯')}")
                sys.exit(1)
    
    except KeyboardInterrupt:
        print("\néƒ¨ç½²å·²å–æ¶ˆ")
    except Exception as e:
        print(f"âŒ éƒ¨ç½²å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()