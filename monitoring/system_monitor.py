"""
PC28 ç³»ç»Ÿç›‘æ§å’ŒæŠ¥å‘Šç³»ç»Ÿ
æä¾›å®æ—¶ç›‘æ§ã€æ€§èƒ½åˆ†æã€é”™è¯¯è·Ÿè¸ªå’Œè‡ªåŠ¨åŒ–æŠ¥å‘ŠåŠŸèƒ½
"""

import os
import json
import time
import psutil
import sqlite3
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor
import threading
from collections import defaultdict, deque

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SystemMetrics:
    """ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    timestamp: str
    cpu_percent: float
    memory_percent: float
    memory_used_gb: float
    memory_total_gb: float
    disk_percent: float
    disk_used_gb: float
    disk_total_gb: float
    network_sent_mb: float
    network_recv_mb: float
    active_connections: int
    process_count: int

@dataclass
class DatabaseMetrics:
    """æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡"""
    timestamp: str
    database_name: str
    table_count: int
    total_records: int
    database_size_mb: float
    query_response_time_ms: float
    active_connections: int
    last_sync_time: Optional[str]
    sync_status: str

@dataclass
class SyncMetrics:
    """åŒæ­¥æ€§èƒ½æŒ‡æ ‡"""
    timestamp: str
    sync_id: str
    table_name: str
    records_processed: int
    records_synced: int
    sync_duration_seconds: float
    sync_status: str
    error_count: int
    throughput_records_per_second: float

@dataclass
class AlertEvent:
    """å‘Šè­¦äº‹ä»¶"""
    timestamp: str
    alert_id: str
    severity: str  # INFO, WARNING, ERROR, CRITICAL
    category: str  # SYSTEM, DATABASE, SYNC, SECURITY
    message: str
    details: Dict[str, Any]
    resolved: bool = False
    resolved_at: Optional[str] = None

class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self, monitoring_interval: int = 60):
        """
        åˆå§‹åŒ–ç³»ç»Ÿç›‘æ§å™¨
        
        Args:
            monitoring_interval: ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
        """
        self.monitoring_interval = monitoring_interval
        self.is_monitoring = False
        self.monitoring_thread = None
        
        # æ•°æ®å­˜å‚¨
        self.metrics_history = deque(maxlen=1440)  # ä¿ç•™24å°æ—¶çš„æ•°æ®ï¼ˆæ¯åˆ†é’Ÿä¸€ä¸ªç‚¹ï¼‰
        self.database_metrics = {}
        self.sync_metrics = deque(maxlen=1000)
        self.alert_events = deque(maxlen=500)
        
        # å‘Šè­¦é˜ˆå€¼
        self.alert_thresholds = {
            'cpu_percent': 80.0,
            'memory_percent': 85.0,
            'disk_percent': 90.0,
            'sync_failure_rate': 0.1,  # 10%
            'query_response_time_ms': 5000.0,  # 5ç§’
            'sync_duration_threshold': 300.0  # 5åˆ†é’Ÿ
        }
        
        # ç½‘ç»œåŸºçº¿ï¼ˆç”¨äºè®¡ç®—å¢é‡ï¼‰
        self.network_baseline = None
        
        # åˆå§‹åŒ–ç›‘æ§æ•°æ®åº“
        self._init_monitoring_database()
    
    def _init_monitoring_database(self):
        """åˆå§‹åŒ–ç›‘æ§æ•°æ®åº“"""
        self.monitoring_db_path = 'monitoring/monitoring_data.db'
        os.makedirs(os.path.dirname(self.monitoring_db_path), exist_ok=True)
        
        try:
            with sqlite3.connect(self.monitoring_db_path) as conn:
                cursor = conn.cursor()
                
                # ç³»ç»ŸæŒ‡æ ‡è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS system_metrics (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        cpu_percent REAL,
                        memory_percent REAL,
                        memory_used_gb REAL,
                        memory_total_gb REAL,
                        disk_percent REAL,
                        disk_used_gb REAL,
                        disk_total_gb REAL,
                        network_sent_mb REAL,
                        network_recv_mb REAL,
                        active_connections INTEGER,
                        process_count INTEGER
                    )
                ''')
                
                # æ•°æ®åº“æŒ‡æ ‡è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS database_metrics (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        database_name TEXT NOT NULL,
                        table_count INTEGER,
                        total_records INTEGER,
                        database_size_mb REAL,
                        query_response_time_ms REAL,
                        active_connections INTEGER,
                        last_sync_time TEXT,
                        sync_status TEXT
                    )
                ''')
                
                # åŒæ­¥æŒ‡æ ‡è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS sync_metrics (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        sync_id TEXT NOT NULL,
                        table_name TEXT NOT NULL,
                        records_processed INTEGER,
                        records_synced INTEGER,
                        sync_duration_seconds REAL,
                        sync_status TEXT,
                        error_count INTEGER,
                        throughput_records_per_second REAL
                    )
                ''')
                
                # å‘Šè­¦äº‹ä»¶è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS alert_events (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        alert_id TEXT UNIQUE NOT NULL,
                        severity TEXT NOT NULL,
                        category TEXT NOT NULL,
                        message TEXT NOT NULL,
                        details TEXT,
                        resolved BOOLEAN DEFAULT FALSE,
                        resolved_at TEXT
                    )
                ''')
                
                # åˆ›å»ºç´¢å¼•
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_system_metrics_timestamp ON system_metrics(timestamp)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_database_metrics_timestamp ON database_metrics(timestamp)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_sync_metrics_timestamp ON sync_metrics(timestamp)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_alert_events_timestamp ON alert_events(timestamp)')
                
                conn.commit()
                logger.info("Monitoring database initialized successfully")
                
        except Exception as e:
            logger.error(f"Failed to initialize monitoring database: {e}")
    
    def collect_system_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        try:
            # CPU ä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä½¿ç”¨æƒ…å†µ
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_used_gb = memory.used / (1024**3)
            memory_total_gb = memory.total / (1024**3)
            
            # ç£ç›˜ä½¿ç”¨æƒ…å†µ
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            disk_used_gb = disk.used / (1024**3)
            disk_total_gb = disk.total / (1024**3)
            
            # ç½‘ç»œä½¿ç”¨æƒ…å†µ
            network = psutil.net_io_counters()
            if self.network_baseline is None:
                self.network_baseline = network
                network_sent_mb = 0
                network_recv_mb = 0
            else:
                network_sent_mb = (network.bytes_sent - self.network_baseline.bytes_sent) / (1024**2)
                network_recv_mb = (network.bytes_recv - self.network_baseline.bytes_recv) / (1024**2)
            
            # è¿›ç¨‹å’Œè¿æ¥æ•°
            process_count = len(psutil.pids())
            
            # æ´»è·ƒè¿æ¥æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            try:
                active_connections = len(psutil.net_connections())
            except (psutil.AccessDenied, psutil.NoSuchProcess):
                active_connections = 0
            
            metrics = SystemMetrics(
                timestamp=datetime.now().isoformat(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                memory_used_gb=memory_used_gb,
                memory_total_gb=memory_total_gb,
                disk_percent=disk_percent,
                disk_used_gb=disk_used_gb,
                disk_total_gb=disk_total_gb,
                network_sent_mb=network_sent_mb,
                network_recv_mb=network_recv_mb,
                active_connections=active_connections,
                process_count=process_count
            )
            
            return metrics
            
        except Exception as e:
            logger.error(f"Failed to collect system metrics: {e}")
            return None
    
    def collect_database_metrics(self, db_path: str, db_name: str) -> DatabaseMetrics:
        """æ”¶é›†æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡"""
        try:
            start_time = time.time()
            
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                
                # æŸ¥è¯¢å“åº”æ—¶é—´æµ‹è¯•
                cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
                table_count = cursor.fetchone()[0]
                
                query_response_time_ms = (time.time() - start_time) * 1000
                
                # è®¡ç®—æ€»è®°å½•æ•°
                total_records = 0
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = cursor.fetchall()
                
                for (table_name,) in tables:
                    try:
                        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                        count = cursor.fetchone()[0]
                        total_records += count
                    except Exception:
                        continue
                
                # æ•°æ®åº“æ–‡ä»¶å¤§å°
                database_size_mb = os.path.getsize(db_path) / (1024**2) if os.path.exists(db_path) else 0
                
                # è·å–æœ€ååŒæ­¥æ—¶é—´ï¼ˆå¦‚æœå­˜åœ¨ sync_status è¡¨ï¼‰
                last_sync_time = None
                sync_status = "unknown"
                try:
                    cursor.execute("SELECT last_sync_time, status FROM sync_status ORDER BY last_sync_time DESC LIMIT 1")
                    result = cursor.fetchone()
                    if result:
                        last_sync_time, sync_status = result
                except Exception:
                    pass
                
                metrics = DatabaseMetrics(
                    timestamp=datetime.now().isoformat(),
                    database_name=db_name,
                    table_count=table_count,
                    total_records=total_records,
                    database_size_mb=database_size_mb,
                    query_response_time_ms=query_response_time_ms,
                    active_connections=1,  # SQLite å•è¿æ¥
                    last_sync_time=last_sync_time,
                    sync_status=sync_status
                )
                
                return metrics
                
        except Exception as e:
            logger.error(f"Failed to collect database metrics for {db_name}: {e}")
            return None
    
    def record_sync_metrics(self, sync_id: str, table_name: str, 
                          records_processed: int, records_synced: int,
                          sync_duration_seconds: float, sync_status: str,
                          error_count: int = 0):
        """è®°å½•åŒæ­¥æ€§èƒ½æŒ‡æ ‡"""
        try:
            throughput = records_synced / sync_duration_seconds if sync_duration_seconds > 0 else 0
            
            metrics = SyncMetrics(
                timestamp=datetime.now().isoformat(),
                sync_id=sync_id,
                table_name=table_name,
                records_processed=records_processed,
                records_synced=records_synced,
                sync_duration_seconds=sync_duration_seconds,
                sync_status=sync_status,
                error_count=error_count,
                throughput_records_per_second=throughput
            )
            
            self.sync_metrics.append(metrics)
            self._save_sync_metrics(metrics)
            
            # æ£€æŸ¥åŒæ­¥å‘Šè­¦
            self._check_sync_alerts(metrics)
            
        except Exception as e:
            logger.error(f"Failed to record sync metrics: {e}")
    
    def create_alert(self, severity: str, category: str, message: str, 
                    details: Dict[str, Any] = None):
        """åˆ›å»ºå‘Šè­¦äº‹ä»¶"""
        try:
            alert_id = f"{category}_{severity}_{int(time.time())}"
            
            alert = AlertEvent(
                timestamp=datetime.now().isoformat(),
                alert_id=alert_id,
                severity=severity,
                category=category,
                message=message,
                details=details or {}
            )
            
            self.alert_events.append(alert)
            self._save_alert_event(alert)
            
            logger.warning(f"Alert created: [{severity}] {category} - {message}")
            
        except Exception as e:
            logger.error(f"Failed to create alert: {e}")
    
    def _check_system_alerts(self, metrics: SystemMetrics):
        """æ£€æŸ¥ç³»ç»Ÿå‘Šè­¦"""
        if metrics.cpu_percent > self.alert_thresholds['cpu_percent']:
            self.create_alert(
                "WARNING", "SYSTEM",
                f"High CPU usage: {metrics.cpu_percent:.1f}%",
                {"cpu_percent": metrics.cpu_percent, "threshold": self.alert_thresholds['cpu_percent']}
            )
        
        if metrics.memory_percent > self.alert_thresholds['memory_percent']:
            self.create_alert(
                "WARNING", "SYSTEM",
                f"High memory usage: {metrics.memory_percent:.1f}%",
                {"memory_percent": metrics.memory_percent, "threshold": self.alert_thresholds['memory_percent']}
            )
        
        if metrics.disk_percent > self.alert_thresholds['disk_percent']:
            self.create_alert(
                "CRITICAL", "SYSTEM",
                f"High disk usage: {metrics.disk_percent:.1f}%",
                {"disk_percent": metrics.disk_percent, "threshold": self.alert_thresholds['disk_percent']}
            )
    
    def _check_database_alerts(self, metrics: DatabaseMetrics):
        """æ£€æŸ¥æ•°æ®åº“å‘Šè­¦"""
        if metrics.query_response_time_ms > self.alert_thresholds['query_response_time_ms']:
            self.create_alert(
                "WARNING", "DATABASE",
                f"Slow database query: {metrics.query_response_time_ms:.1f}ms",
                {"database": metrics.database_name, "response_time": metrics.query_response_time_ms}
            )
    
    def _check_sync_alerts(self, metrics: SyncMetrics):
        """æ£€æŸ¥åŒæ­¥å‘Šè­¦"""
        if metrics.sync_status == "failed":
            self.create_alert(
                "ERROR", "SYNC",
                f"Sync failed for table {metrics.table_name}",
                {"table_name": metrics.table_name, "sync_id": metrics.sync_id}
            )
        
        if metrics.sync_duration_seconds > self.alert_thresholds['sync_duration_threshold']:
            self.create_alert(
                "WARNING", "SYNC",
                f"Long sync duration for table {metrics.table_name}: {metrics.sync_duration_seconds:.1f}s",
                {"table_name": metrics.table_name, "duration": metrics.sync_duration_seconds}
            )
    
    def _save_system_metrics(self, metrics: SystemMetrics):
        """ä¿å­˜ç³»ç»ŸæŒ‡æ ‡åˆ°æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.monitoring_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO system_metrics (
                        timestamp, cpu_percent, memory_percent, memory_used_gb, memory_total_gb,
                        disk_percent, disk_used_gb, disk_total_gb, network_sent_mb, network_recv_mb,
                        active_connections, process_count
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    metrics.timestamp, metrics.cpu_percent, metrics.memory_percent,
                    metrics.memory_used_gb, metrics.memory_total_gb, metrics.disk_percent,
                    metrics.disk_used_gb, metrics.disk_total_gb, metrics.network_sent_mb,
                    metrics.network_recv_mb, metrics.active_connections, metrics.process_count
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Failed to save system metrics: {e}")
    
    def _save_database_metrics(self, metrics: DatabaseMetrics):
        """ä¿å­˜æ•°æ®åº“æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.monitoring_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO database_metrics (
                        timestamp, database_name, table_count, total_records, database_size_mb,
                        query_response_time_ms, active_connections, last_sync_time, sync_status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    metrics.timestamp, metrics.database_name, metrics.table_count,
                    metrics.total_records, metrics.database_size_mb, metrics.query_response_time_ms,
                    metrics.active_connections, metrics.last_sync_time, metrics.sync_status
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Failed to save database metrics: {e}")
    
    def _save_sync_metrics(self, metrics: SyncMetrics):
        """ä¿å­˜åŒæ­¥æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.monitoring_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO sync_metrics (
                        timestamp, sync_id, table_name, records_processed, records_synced,
                        sync_duration_seconds, sync_status, error_count, throughput_records_per_second
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    metrics.timestamp, metrics.sync_id, metrics.table_name,
                    metrics.records_processed, metrics.records_synced, metrics.sync_duration_seconds,
                    metrics.sync_status, metrics.error_count, metrics.throughput_records_per_second
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Failed to save sync metrics: {e}")
    
    def _save_alert_event(self, alert: AlertEvent):
        """ä¿å­˜å‘Šè­¦äº‹ä»¶åˆ°æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.monitoring_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT OR REPLACE INTO alert_events (
                        timestamp, alert_id, severity, category, message, details, resolved, resolved_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    alert.timestamp, alert.alert_id, alert.severity, alert.category,
                    alert.message, json.dumps(alert.details), alert.resolved, alert.resolved_at
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Failed to save alert event: {e}")
    
    def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§"""
        if self.is_monitoring:
            logger.warning("Monitoring is already running")
            return
        
        self.is_monitoring = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        logger.info("System monitoring started")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_monitoring = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        logger.info("System monitoring stopped")
    
    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                system_metrics = self.collect_system_metrics()
                if system_metrics:
                    self.metrics_history.append(system_metrics)
                    self._save_system_metrics(system_metrics)
                    self._check_system_alerts(system_metrics)
                
                # æ”¶é›†æ•°æ®åº“æŒ‡æ ‡
                db_configs = [
                    ('pc28_data.db', 'PC28_Main'),
                    ('test_pc28_data.db', 'PC28_Test')
                ]
                
                for db_path, db_name in db_configs:
                    if os.path.exists(db_path):
                        db_metrics = self.collect_database_metrics(db_path, db_name)
                        if db_metrics:
                            self.database_metrics[db_name] = db_metrics
                            self._save_database_metrics(db_metrics)
                            self._check_database_alerts(db_metrics)
                
                # ç­‰å¾…ä¸‹ä¸€ä¸ªç›‘æ§å‘¨æœŸ
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                time.sleep(self.monitoring_interval)
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€æ‘˜è¦"""
        try:
            current_metrics = self.metrics_history[-1] if self.metrics_history else None
            
            # è®¡ç®—å¹³å‡å€¼ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰
            recent_metrics = list(self.metrics_history)[-60:] if len(self.metrics_history) >= 60 else list(self.metrics_history)
            
            avg_cpu = sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics) if recent_metrics else 0
            avg_memory = sum(m.memory_percent for m in recent_metrics) / len(recent_metrics) if recent_metrics else 0
            
            # ç»Ÿè®¡å‘Šè­¦
            recent_alerts = [a for a in self.alert_events if not a.resolved]
            alert_counts = defaultdict(int)
            for alert in recent_alerts:
                alert_counts[alert.severity] += 1
            
            # åŒæ­¥çŠ¶æ€
            recent_syncs = list(self.sync_metrics)[-10:] if self.sync_metrics else []
            successful_syncs = sum(1 for s in recent_syncs if s.sync_status == "success")
            sync_success_rate = successful_syncs / len(recent_syncs) if recent_syncs else 0
            
            status = {
                'timestamp': datetime.now().isoformat(),
                'system': {
                    'status': 'healthy' if current_metrics and current_metrics.cpu_percent < 80 and current_metrics.memory_percent < 85 else 'warning',
                    'cpu_percent': current_metrics.cpu_percent if current_metrics else 0,
                    'memory_percent': current_metrics.memory_percent if current_metrics else 0,
                    'disk_percent': current_metrics.disk_percent if current_metrics else 0,
                    'avg_cpu_1h': avg_cpu,
                    'avg_memory_1h': avg_memory
                },
                'database': {
                    'databases': len(self.database_metrics),
                    'status': 'healthy',  # ç®€åŒ–ç‰ˆæœ¬
                    'total_tables': sum(db.table_count for db in self.database_metrics.values()),
                    'total_records': sum(db.total_records for db in self.database_metrics.values())
                },
                'sync': {
                    'recent_syncs': len(recent_syncs),
                    'success_rate': sync_success_rate,
                    'status': 'healthy' if sync_success_rate > 0.9 else 'warning'
                },
                'alerts': {
                    'total_active': len(recent_alerts),
                    'critical': alert_counts['CRITICAL'],
                    'error': alert_counts['ERROR'],
                    'warning': alert_counts['WARNING'],
                    'info': alert_counts['INFO']
                }
            }
            
            return status
            
        except Exception as e:
            logger.error(f"Failed to get system status: {e}")
            return {'error': str(e)}
    
    def generate_monitoring_report(self, hours: int = 24) -> str:
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        try:
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)
            
            # æŸ¥è¯¢å†å²æ•°æ®
            with sqlite3.connect(self.monitoring_db_path) as conn:
                cursor = conn.cursor()
                
                # ç³»ç»ŸæŒ‡æ ‡ç»Ÿè®¡
                cursor.execute('''
                    SELECT AVG(cpu_percent), AVG(memory_percent), AVG(disk_percent),
                           MAX(cpu_percent), MAX(memory_percent), MAX(disk_percent)
                    FROM system_metrics 
                    WHERE timestamp >= ?
                ''', (start_time.isoformat(),))
                
                system_stats = cursor.fetchone()
                
                # åŒæ­¥ç»Ÿè®¡
                cursor.execute('''
                    SELECT COUNT(*), 
                           SUM(CASE WHEN sync_status = 'success' THEN 1 ELSE 0 END),
                           AVG(sync_duration_seconds),
                           SUM(records_synced)
                    FROM sync_metrics 
                    WHERE timestamp >= ?
                ''', (start_time.isoformat(),))
                
                sync_stats = cursor.fetchone()
                
                # å‘Šè­¦ç»Ÿè®¡
                cursor.execute('''
                    SELECT severity, COUNT(*) 
                    FROM alert_events 
                    WHERE timestamp >= ? 
                    GROUP BY severity
                ''', (start_time.isoformat(),))
                
                alert_stats = dict(cursor.fetchall())
            
            # ç”ŸæˆæŠ¥å‘Š
            report_lines = [
                f"# PC28 ç³»ç»Ÿç›‘æ§æŠ¥å‘Š",
                f"",
                f"**æŠ¥å‘Šæ—¶é—´**: {end_time.strftime('%Y-%m-%d %H:%M:%S')}",
                f"**ç»Ÿè®¡å‘¨æœŸ**: æœ€è¿‘ {hours} å°æ—¶",
                f"",
                f"## ç³»ç»Ÿæ€§èƒ½æ¦‚è§ˆ",
                f"",
                f"### CPU ä½¿ç”¨ç‡",
                f"- å¹³å‡: {system_stats[0]:.1f}%" if system_stats[0] else "- å¹³å‡: N/A",
                f"- å³°å€¼: {system_stats[3]:.1f}%" if system_stats[3] else "- å³°å€¼: N/A",
                f"",
                f"### å†…å­˜ä½¿ç”¨ç‡",
                f"- å¹³å‡: {system_stats[1]:.1f}%" if system_stats[1] else "- å¹³å‡: N/A",
                f"- å³°å€¼: {system_stats[4]:.1f}%" if system_stats[4] else "- å³°å€¼: N/A",
                f"",
                f"### ç£ç›˜ä½¿ç”¨ç‡",
                f"- å¹³å‡: {system_stats[2]:.1f}%" if system_stats[2] else "- å¹³å‡: N/A",
                f"- å³°å€¼: {system_stats[5]:.1f}%" if system_stats[5] else "- å³°å€¼: N/A",
                f"",
                f"## æ•°æ®åŒæ­¥ç»Ÿè®¡",
                f"",
                f"- æ€»åŒæ­¥æ¬¡æ•°: {sync_stats[0] or 0}",
                f"- æˆåŠŸæ¬¡æ•°: {sync_stats[1] or 0}",
                f"- æˆåŠŸç‡: {(sync_stats[1] / sync_stats[0] * 100):.1f}%" if sync_stats[0] and sync_stats[1] else "- æˆåŠŸç‡: N/A",
                f"- å¹³å‡åŒæ­¥æ—¶é—´: {sync_stats[2]:.1f}ç§’" if sync_stats[2] else "- å¹³å‡åŒæ­¥æ—¶é—´: N/A",
                f"- æ€»åŒæ­¥è®°å½•æ•°: {sync_stats[3] or 0}",
                f"",
                f"## å‘Šè­¦ç»Ÿè®¡",
                f""
            ]
            
            if alert_stats:
                for severity, count in alert_stats.items():
                    report_lines.append(f"- {severity}: {count} æ¬¡")
            else:
                report_lines.append("- æ— å‘Šè­¦äº‹ä»¶")
            
            report_lines.extend([
                f"",
                f"## ç³»ç»Ÿå¥åº·çŠ¶æ€",
                f"",
                f"- ç³»ç»ŸçŠ¶æ€: {'ğŸŸ¢ å¥åº·' if (system_stats[3] or 0) < 80 and (system_stats[4] or 0) < 85 else 'ğŸŸ¡ éœ€è¦å…³æ³¨'}",
                f"- åŒæ­¥çŠ¶æ€: {'ğŸŸ¢ æ­£å¸¸' if (sync_stats[1] or 0) / (sync_stats[0] or 1) > 0.9 else 'ğŸŸ¡ éœ€è¦å…³æ³¨'}",
                f"- å‘Šè­¦çŠ¶æ€: {'ğŸŸ¢ æ­£å¸¸' if alert_stats.get('CRITICAL', 0) == 0 and alert_stats.get('ERROR', 0) == 0 else 'ğŸ”´ éœ€è¦å¤„ç†'}",
                f"",
                f"---",
                f"*æŠ¥å‘Šç”± PC28 ç›‘æ§ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*"
            ])
            
            return "\n".join(report_lines)
            
        except Exception as e:
            logger.error(f"Failed to generate monitoring report: {e}")
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"


# å…¨å±€ç›‘æ§å®ä¾‹
system_monitor = SystemMonitor()

# ä¾¿æ·å‡½æ•°
def start_system_monitoring():
    """å¯åŠ¨ç³»ç»Ÿç›‘æ§"""
    system_monitor.start_monitoring()

def stop_system_monitoring():
    """åœæ­¢ç³»ç»Ÿç›‘æ§"""
    system_monitor.stop_monitoring()

def get_current_status() -> Dict[str, Any]:
    """è·å–å½“å‰ç³»ç»ŸçŠ¶æ€"""
    return system_monitor.get_system_status()

def record_sync_event(sync_id: str, table_name: str, records_processed: int, 
                     records_synced: int, duration: float, status: str, errors: int = 0):
    """è®°å½•åŒæ­¥äº‹ä»¶"""
    system_monitor.record_sync_metrics(
        sync_id, table_name, records_processed, records_synced, 
        duration, status, errors
    )

def create_system_alert(severity: str, category: str, message: str, details: Dict[str, Any] = None):
    """åˆ›å»ºç³»ç»Ÿå‘Šè­¦"""
    system_monitor.create_alert(severity, category, message, details)


if __name__ == "__main__":
    # æ¼”ç¤ºç”¨æ³•
    print("ğŸ“Š PC28 System Monitor Demo")
    
    # å¯åŠ¨ç›‘æ§
    start_system_monitoring()
    
    # ç­‰å¾…ä¸€äº›æ•°æ®æ”¶é›†
    print("â³ Collecting metrics for 10 seconds...")
    time.sleep(10)
    
    # è·å–ç³»ç»ŸçŠ¶æ€
    status = get_current_status()
    print(f"\nğŸ–¥ï¸ System Status:")
    print(f"  CPU: {status['system']['cpu_percent']:.1f}%")
    print(f"  Memory: {status['system']['memory_percent']:.1f}%")
    print(f"  Disk: {status['system']['disk_percent']:.1f}%")
    
    # æ¨¡æ‹Ÿä¸€äº›åŒæ­¥äº‹ä»¶
    print("\nğŸ”„ Simulating sync events...")
    record_sync_event("sync_001", "test_table", 1000, 1000, 5.2, "success")
    record_sync_event("sync_002", "test_table2", 500, 450, 12.8, "partial", 50)
    
    # åˆ›å»ºæµ‹è¯•å‘Šè­¦
    create_system_alert("WARNING", "SYSTEM", "Test alert for demonstration", 
                       {"test_value": 123, "threshold": 100})
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“„ Generating monitoring report...")
    report = system_monitor.generate_monitoring_report(1)  # æœ€è¿‘1å°æ—¶
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = 'monitoring/demo_report.md'
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    with open(report_path, 'w') as f:
        f.write(report)
    
    print(f"âœ… Report saved to: {report_path}")
    print("\nğŸ“Š Report preview:")
    print(report[:500] + "..." if len(report) > 500 else report)
    
    # åœæ­¢ç›‘æ§
    stop_system_monitoring()
    print("\nğŸ›‘ Monitoring stopped")