#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
APIé›†æˆæµ‹è¯•è„šæœ¬
æµ‹è¯•åŠ æ‹¿å¤§28ä¸Šæ¸¸APIçš„è¿æ¥ã€ç­¾åéªŒè¯å’Œæ•°æ®è·å–åŠŸèƒ½
"""

import json
import logging
import sys
import os
from datetime import datetime, timedelta
from typing import Dict, Any, List

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from pc28_upstream_api import PC28UpstreamAPI
from realtime_lottery_service import RealtimeLotteryService
from history_backfill_service import HistoryBackfillService
from integrated_data_adapter import IntegratedDataAdapter

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_test_config() -> Dict[str, Any]:
    """
    åŠ è½½æµ‹è¯•é…ç½®
    """
    config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'integrated_config.json')
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logger.warning(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return {
            "appid": "45928",
            "secret_key": "ca9edbfee35c22a0d6c4cf6722506af0",
            "upstream_api": {
                "appid": "45928",
                "secret_key": "ca9edbfee35c22a0d6c4cf6722506af0",
                "realtime_url": "https://rijb.api.storeapi.net/api/119/259",
                "history_url": "https://rijb.api.storeapi.net/api/119/260",
                "timeout": 30,
                "max_retries": 3
            },
            "data_source": {
                "use_upstream_api": True,
                "fallback_to_bigquery": True,
                "sync_to_bigquery": False,
                "validation_enabled": True
            }
        }

def test_md5_signature():
    """
    æµ‹è¯•MD5ç­¾åç”ŸæˆåŠŸèƒ½
    """
    logger.info("=== æµ‹è¯•MD5ç­¾åç”Ÿæˆ ===")
    
    config = load_test_config()
    api_client = PC28UpstreamAPI(config['upstream_api']['appid'], config['upstream_api']['secret_key'])
    
    # æµ‹è¯•å®æ—¶æ¥å£ç­¾å
    params = {
        'appid': '45928',
        'format': 'json',
        'time': '1545829466'
    }
    
    signature = api_client._generate_md5_sign(params)
    logger.info(f"å®æ—¶æ¥å£ç­¾å: {signature}")
    
    # æµ‹è¯•å†å²æ¥å£ç­¾å
    history_params = {
        'appid': '45928',
        'date': '2020-12-16',
        'format': 'json',
        'limit': '30',
        'time': '1545829466'
    }
    
    history_signature = api_client._generate_md5_sign(history_params)
    logger.info(f"å†å²æ¥å£ç­¾å: {history_signature}")
    
    return True

def test_api_connectivity():
    """
    æµ‹è¯•APIè¿æ¥æ€§
    """
    logger.info("=== æµ‹è¯•APIè¿æ¥æ€§ ===")
    
    config = load_test_config()
    api_client = PC28UpstreamAPI(config['upstream_api']['appid'], config['upstream_api']['secret_key'])
    
    # æµ‹è¯•å®æ—¶æ¥å£
    try:
        realtime_response = api_client.get_realtime_lottery()
        realtime_success = realtime_response and realtime_response.get('codeid') == 10000
    except Exception as e:
        logger.error(f"å®æ—¶æ¥å£æµ‹è¯•å¤±è´¥: {e}")
        realtime_success = False
    
    # æµ‹è¯•å†å²æ¥å£
    try:
        history_response = api_client.get_history_lottery(date='2024-12-19', limit=1)
        history_success = history_response and history_response.get('codeid') == 10000
    except Exception as e:
        logger.error(f"å†å²æ¥å£æµ‹è¯•å¤±è´¥: {e}")
        history_success = False
    
    connectivity_result = {
        'realtime': {'success': realtime_success, 'response_time': 0.0, 'error': None},
        'history': {'success': history_success, 'response_time': 0.0, 'error': None}
    }
    
    if connectivity_result['realtime']['success']:
        logger.info("âœ“ å®æ—¶æ¥å£è¿æ¥æˆåŠŸ")
        logger.info(f"  å“åº”æ—¶é—´: {connectivity_result['realtime']['response_time']:.2f}s")
    else:
        logger.error("âœ— å®æ—¶æ¥å£è¿æ¥å¤±è´¥")
        logger.error(f"  é”™è¯¯: {connectivity_result['realtime']['error']}")
    
    if connectivity_result['history']['success']:
        logger.info("âœ“ å†å²æ¥å£è¿æ¥æˆåŠŸ")
        logger.info(f"  å“åº”æ—¶é—´: {connectivity_result['history']['response_time']:.2f}s")
    else:
        logger.error("âœ— å†å²æ¥å£è¿æ¥å¤±è´¥")
        logger.error(f"  é”™è¯¯: {connectivity_result['history']['error']}")
    
    return connectivity_result

def test_realtime_data_fetch():
    """
    æµ‹è¯•å®æ—¶æ•°æ®è·å–
    """
    logger.info("=== æµ‹è¯•å®æ—¶æ•°æ®è·å– ===")
    
    config = load_test_config()
    realtime_service = RealtimeLotteryService(config['upstream_api']['appid'], config['upstream_api']['secret_key'])
    
    try:
        # è·å–å½“å‰å¼€å¥–ä¿¡æ¯
        current_draw = realtime_service.fetch_current_draw()
        if current_draw:
            logger.info("âœ“ æˆåŠŸè·å–å½“å‰å¼€å¥–ä¿¡æ¯")
            logger.info(f"  æœŸå·: {current_draw.get('draw_id')}")
            logger.info(f"  å¼€å¥–æ—¶é—´: {current_draw.get('timestamp')}")
            logger.info(f"  å¼€å¥–å·ç : {current_draw.get('numbers')}")
            logger.info(f"  å’Œå€¼: {current_draw.get('result_sum')}")
        else:
            logger.warning("âš  æœªè·å–åˆ°å½“å‰å¼€å¥–ä¿¡æ¯")
        
        # è·å–ä¸‹æœŸå¼€å¥–ä¿¡æ¯
        next_draw = realtime_service.get_next_draw_info()
        if next_draw:
            logger.info("âœ“ æˆåŠŸè·å–ä¸‹æœŸå¼€å¥–ä¿¡æ¯")
            logger.info(f"  ä¸‹æœŸæœŸå·: {next_draw.get('next_issue')}")
            logger.info(f"  ä¸‹æœŸå¼€å¥–æ—¶é—´: {next_draw.get('next_time')}")
            logger.info(f"  è·ç¦»å¼€å¥–: {next_draw.get('award_time')}ç§’")
        else:
            logger.warning("âš  æœªè·å–åˆ°ä¸‹æœŸå¼€å¥–ä¿¡æ¯")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— å®æ—¶æ•°æ®è·å–å¤±è´¥: {e}")
        return False

def test_history_data_fetch():
    """
    æµ‹è¯•å†å²æ•°æ®è·å–
    """
    logger.info("=== æµ‹è¯•å†å²æ•°æ®è·å– ===")
    
    config = load_test_config()
    backfill_service = HistoryBackfillService(config['upstream_api']['appid'], config['upstream_api']['secret_key'])
    
    try:
        # è·å–æ˜¨å¤©çš„æ•°æ®
        yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        data_list = backfill_service.fetch_history_by_date(yesterday, limit=5)
        
        if data_list:
            logger.info(f"âœ“ æˆåŠŸè·å– {yesterday} çš„å†å²æ•°æ®")
            logger.info(f"  è·å–è®°å½•æ•°: {len(data_list)}")
            
            # æ˜¾ç¤ºå‰å‡ æ¡è®°å½•
            for i, record in enumerate(data_list[:3]):
                logger.info(f"  è®°å½•{i+1}: æœŸå·={record.get('draw_id')}, "
                          f"æ—¶é—´={record.get('timestamp')}, å·ç ={record.get('numbers')}, å’Œå€¼={record.get('result_sum')}")
        else:
            logger.error(f"âœ— å†å²æ•°æ®è·å–å¤±è´¥")
            return False
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— å†å²æ•°æ®è·å–å¼‚å¸¸: {e}")
        return False

def test_integrated_adapter():
    """
    æµ‹è¯•é›†æˆæ•°æ®é€‚é…å™¨
    """
    logger.info("=== æµ‹è¯•é›†æˆæ•°æ®é€‚é…å™¨ ===")
    
    try:
        config = load_test_config()
        
        # æ¨¡æ‹ŸBigQueryç¯å¢ƒå˜é‡ï¼ˆæµ‹è¯•æ—¶å¯èƒ½ä¸å­˜åœ¨ï¼‰
        os.environ.setdefault('GOOGLE_CLOUD_PROJECT', 'test-project')
        
        # åˆ›å»ºæµ‹è¯•é…ç½®
        test_config = {
            'bigquery': {
                'project': 'test-project',
                'dataset_lab': 'test_lab',
                'dataset_draw': 'test_draw',
                'location': 'US',
                'timezone': 'UTC'
            },
            'upstream_api': config['upstream_api'],
            'data_source': {
                'use_upstream_api': True,
                'fallback_to_bigquery': False,
                'sync_to_bigquery': False,
                'validation_enabled': False
            }
        }
        
        adapter = IntegratedDataAdapter(test_config)
        
        # æµ‹è¯•è·å–å½“å‰å¼€å¥–ä¿¡æ¯
        current_info = adapter.get_current_draw_info()
        if current_info:
            logger.info("âœ“ é›†æˆé€‚é…å™¨æˆåŠŸè·å–å½“å‰å¼€å¥–ä¿¡æ¯")
            logger.info(f"  æ•°æ®æº: {current_info.get('source', 'unknown')}")
        else:
            logger.warning("âš  é›†æˆé€‚é…å™¨æœªè·å–åˆ°å½“å‰å¼€å¥–ä¿¡æ¯")
        
        # æµ‹è¯•æ£€æŸ¥æ–°å¼€å¥–æ•°æ®
        new_draws = adapter.check_for_new_draws()
        if new_draws:
            logger.info(f"âœ“ æ£€æµ‹åˆ° {len(new_draws)} æ¡æ–°å¼€å¥–æ•°æ®")
        else:
            logger.info("â„¹ æš‚æ— æ–°å¼€å¥–æ•°æ®")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— é›†æˆé€‚é…å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_comprehensive_test():
    """
    è¿è¡Œç»¼åˆæµ‹è¯•
    """
    logger.info("å¼€å§‹APIé›†æˆç»¼åˆæµ‹è¯•")
    logger.info("=" * 50)
    
    test_results = {
        'md5_signature': False,
        'api_connectivity': False,
        'realtime_data': False,
        'history_data': False,
        'integrated_adapter': False
    }
    
    try:
        # 1. æµ‹è¯•MD5ç­¾å
        test_results['md5_signature'] = test_md5_signature()
        
        # 2. æµ‹è¯•APIè¿æ¥æ€§
        connectivity_result = test_api_connectivity()
        test_results['api_connectivity'] = (
            connectivity_result['realtime']['success'] and 
            connectivity_result['history']['success']
        )
        
        # 3. æµ‹è¯•å®æ—¶æ•°æ®è·å–
        if test_results['api_connectivity']:
            test_results['realtime_data'] = test_realtime_data_fetch()
        
        # 4. æµ‹è¯•å†å²æ•°æ®è·å–
        if test_results['api_connectivity']:
            test_results['history_data'] = test_history_data_fetch()
        
        # 5. æµ‹è¯•é›†æˆé€‚é…å™¨
        test_results['integrated_adapter'] = test_integrated_adapter()
        
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    logger.info("=" * 50)
    logger.info("æµ‹è¯•ç»“æœæ‘˜è¦:")
    
    passed_tests = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
        if result:
            passed_tests += 1
    
    success_rate = (passed_tests / total_tests) * 100
    logger.info(f"\næ€»ä½“æµ‹è¯•é€šè¿‡ç‡: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        logger.info("ğŸ‰ APIé›†æˆæµ‹è¯•åŸºæœ¬é€šè¿‡ï¼")
        return True
    else:
        logger.warning("âš ï¸ APIé›†æˆæµ‹è¯•å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        return False

if __name__ == '__main__':
    success = run_comprehensive_test()
    sys.exit(0 if success else 1)