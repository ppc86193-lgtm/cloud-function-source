#!/usr/bin/env python3
"""
PC28ç»¼åˆä¸šåŠ¡æµ‹è¯•ç³»ç»Ÿ
è¿è¡Œå®Œæ•´çš„ä¸šåŠ¡åŠŸèƒ½æµ‹è¯•ï¼ŒéªŒè¯ç³»ç»Ÿç¨³å®šæ€§å’Œæ•°æ®å®Œæ•´æ€§
"""

import logging
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from google.cloud import bigquery
from dataclasses import dataclass

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class BusinessTestResult:
    """ä¸šåŠ¡æµ‹è¯•ç»“æœ"""
    test_name: str
    test_category: str
    status: str  # 'pass', 'fail', 'skip'
    message: str
    duration: float
    data_count: Optional[int] = None
    error_details: Optional[str] = None
    timestamp: Optional[str] = None

class PC28ComprehensiveBusinessTest:
    def __init__(self):
        self.client = bigquery.Client()
        self.project_id = "wprojectl"
        self.dataset_id = "pc28_lab"
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.test_results: List[BusinessTestResult] = []
        
    def run_comprehensive_business_tests(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆä¸šåŠ¡æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹PC28ç»¼åˆä¸šåŠ¡æµ‹è¯•...")
        
        start_time = time.time()
        
        test_summary = {
            "test_timestamp": self.timestamp,
            "start_time": datetime.now().isoformat(),
            "test_categories": [],
            "total_tests": 0,
            "passed_tests": 0,
            "failed_tests": 0,
            "skipped_tests": 0,
            "success_rate": 0.0,
            "total_duration": 0.0,
            "system_health": False,
            "test_results": []
        }
        
        # 1. æ•°æ®æºå¥åº·æµ‹è¯•
        self._run_data_source_health_tests()
        
        # 2. æ•°æ®æµå®Œæ•´æ€§æµ‹è¯•
        self._run_data_flow_integrity_tests()
        
        # 3. ä¸šåŠ¡é€»è¾‘æµ‹è¯•
        self._run_business_logic_tests()
        
        # 4. æ€§èƒ½åŸºå‡†æµ‹è¯•
        self._run_performance_benchmark_tests()
        
        # 5. æ•°æ®è´¨é‡æµ‹è¯•
        self._run_data_quality_tests()
        
        # 6. ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•
        self._run_system_stability_tests()
        
        # è®¡ç®—æµ‹è¯•æ‘˜è¦
        total_duration = time.time() - start_time
        
        test_summary["total_tests"] = len(self.test_results)
        test_summary["passed_tests"] = len([r for r in self.test_results if r.status == 'pass'])
        test_summary["failed_tests"] = len([r for r in self.test_results if r.status == 'fail'])
        test_summary["skipped_tests"] = len([r for r in self.test_results if r.status == 'skip'])
        test_summary["success_rate"] = (test_summary["passed_tests"] / test_summary["total_tests"] * 100) if test_summary["total_tests"] > 0 else 0
        test_summary["total_duration"] = total_duration
        test_summary["system_health"] = test_summary["failed_tests"] == 0 and test_summary["passed_tests"] > 0
        test_summary["end_time"] = datetime.now().isoformat()
        
        # æŒ‰ç±»åˆ«åˆ†ç»„æµ‹è¯•ç»“æœ
        categories = {}
        for result in self.test_results:
            if result.test_category not in categories:
                categories[result.test_category] = {
                    "category_name": result.test_category,
                    "total": 0,
                    "passed": 0,
                    "failed": 0,
                    "skipped": 0,
                    "tests": []
                }
            
            categories[result.test_category]["total"] += 1
            categories[result.test_category]["tests"].append({
                "test_name": result.test_name,
                "status": result.status,
                "message": result.message,
                "duration": result.duration,
                "data_count": result.data_count,
                "error_details": result.error_details
            })
            
            if result.status == 'pass':
                categories[result.test_category]["passed"] += 1
            elif result.status == 'fail':
                categories[result.test_category]["failed"] += 1
            else:
                categories[result.test_category]["skipped"] += 1
        
        test_summary["test_categories"] = list(categories.values())
        test_summary["test_results"] = [
            {
                "test_name": r.test_name,
                "test_category": r.test_category,
                "status": r.status,
                "message": r.message,
                "duration": r.duration,
                "data_count": r.data_count,
                "error_details": r.error_details,
                "timestamp": r.timestamp
            }
            for r in self.test_results
        ]
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self._generate_business_test_report(test_summary)
        
        return test_summary
    
    def _run_single_test(self, test_name: str, test_category: str, test_func) -> BusinessTestResult:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        start_time = time.time()
        
        try:
            logger.info(f"  è¿è¡Œæµ‹è¯•: {test_name}")
            result = test_func()
            duration = time.time() - start_time
            
            test_result = BusinessTestResult(
                test_name=test_name,
                test_category=test_category,
                status='pass',
                message=result.get('message', 'æµ‹è¯•é€šè¿‡'),
                duration=duration,
                data_count=result.get('data_count'),
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            duration = time.time() - start_time
            test_result = BusinessTestResult(
                test_name=test_name,
                test_category=test_category,
                status='fail',
                message=f'æµ‹è¯•å¤±è´¥: {str(e)}',
                duration=duration,
                error_details=str(e),
                timestamp=datetime.now().isoformat()
            )
            logger.error(f"    âŒ {test_name}: {e}")
        
        self.test_results.append(test_result)
        return test_result
    
    def _run_data_source_health_tests(self):
        """æ•°æ®æºå¥åº·æµ‹è¯•"""
        logger.info("ğŸ“Š è¿è¡Œæ•°æ®æºå¥åº·æµ‹è¯•...")
        
        # æµ‹è¯•åŸå§‹æ•°æ®è¡¨
        self._run_single_test(
            "cloud_pred_today_norm_health",
            "æ•°æ®æºå¥åº·",
            lambda: self._test_table_health("cloud_pred_today_norm", min_rows=100)
        )
        
        # æµ‹è¯•æ¸…ç†åçš„æ•°æ®è¡¨
        self._run_single_test(
            "p_map_clean_merged_dedup_v_health",
            "æ•°æ®æºå¥åº·",
            lambda: self._test_table_health("p_map_clean_merged_dedup_v", min_rows=100)
        )
        
        self._run_single_test(
            "p_size_clean_merged_dedup_v_health",
            "æ•°æ®æºå¥åº·",
            lambda: self._test_table_health("p_size_clean_merged_dedup_v", min_rows=100)
        )
    
    def _run_data_flow_integrity_tests(self):
        """æ•°æ®æµå®Œæ•´æ€§æµ‹è¯•"""
        logger.info("ğŸ”„ è¿è¡Œæ•°æ®æµå®Œæ•´æ€§æµ‹è¯•...")
        
        # æµ‹è¯•é¢„æµ‹è§†å›¾å±‚
        self._run_single_test(
            "p_cloud_today_v_integrity",
            "æ•°æ®æµå®Œæ•´æ€§",
            lambda: self._test_view_integrity("p_cloud_today_v")
        )
        
        self._run_single_test(
            "p_map_today_v_integrity",
            "æ•°æ®æµå®Œæ•´æ€§",
            lambda: self._test_view_integrity("p_map_today_v")
        )
        
        self._run_single_test(
            "p_size_today_v_integrity",
            "æ•°æ®æµå®Œæ•´æ€§",
            lambda: self._test_view_integrity("p_size_today_v")
        )
        
        # æµ‹è¯•æ ‡å‡†åŒ–è§†å›¾å±‚
        self._run_single_test(
            "p_map_today_canon_v_integrity",
            "æ•°æ®æµå®Œæ•´æ€§",
            lambda: self._test_canonical_view_integrity("p_map_today_canon_v")
        )
        
        self._run_single_test(
            "p_size_today_canon_v_integrity",
            "æ•°æ®æµå®Œæ•´æ€§",
            lambda: self._test_canonical_view_integrity("p_size_today_canon_v")
        )
        
        # æµ‹è¯•ä¿¡å·æ± 
        self._run_single_test(
            "signal_pool_union_v3_integrity",
            "æ•°æ®æµå®Œæ•´æ€§",
            lambda: self._test_signal_pool_integrity()
        )
    
    def _run_business_logic_tests(self):
        """ä¸šåŠ¡é€»è¾‘æµ‹è¯•"""
        logger.info("ğŸ¯ è¿è¡Œä¸šåŠ¡é€»è¾‘æµ‹è¯•...")
        
        # æµ‹è¯•å†³ç­–å€™é€‰ç”Ÿæˆ
        self._run_single_test(
            "lab_push_candidates_v2_logic",
            "ä¸šåŠ¡é€»è¾‘",
            lambda: self._test_decision_candidates_logic()
        )
        
        # æµ‹è¯•è¿è¡Œæ—¶å‚æ•°
        self._run_single_test(
            "runtime_params_logic",
            "ä¸šåŠ¡é€»è¾‘",
            lambda: self._test_runtime_params_logic()
        )
        
        # æµ‹è¯•æ•°æ®å…³è”æ€§
        self._run_single_test(
            "data_correlation_logic",
            "ä¸šåŠ¡é€»è¾‘",
            lambda: self._test_data_correlation()
        )
    
    def _run_performance_benchmark_tests(self):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.info("âš¡ è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        
        # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        self._run_single_test(
            "signal_pool_query_performance",
            "æ€§èƒ½åŸºå‡†",
            lambda: self._test_query_performance("signal_pool_union_v3")
        )
        
        self._run_single_test(
            "candidates_query_performance",
            "æ€§èƒ½åŸºå‡†",
            lambda: self._test_query_performance("lab_push_candidates_v2")
        )
    
    def _run_data_quality_tests(self):
        """æ•°æ®è´¨é‡æµ‹è¯•"""
        logger.info("ğŸ” è¿è¡Œæ•°æ®è´¨é‡æµ‹è¯•...")
        
        # æµ‹è¯•æ•°æ®å®Œæ•´æ€§
        self._run_single_test(
            "signal_pool_data_quality",
            "æ•°æ®è´¨é‡",
            lambda: self._test_signal_pool_data_quality()
        )
        
        # æµ‹è¯•æ•°æ®ä¸€è‡´æ€§
        self._run_single_test(
            "data_consistency_check",
            "æ•°æ®è´¨é‡",
            lambda: self._test_data_consistency()
        )
    
    def _run_system_stability_tests(self):
        """ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•"""
        logger.info("ğŸ›¡ï¸ è¿è¡Œç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•...")
        
        # æµ‹è¯•å¹¶å‘æŸ¥è¯¢
        self._run_single_test(
            "concurrent_query_stability",
            "ç³»ç»Ÿç¨³å®šæ€§",
            lambda: self._test_concurrent_queries()
        )
    
    def _test_table_health(self, table_name: str, min_rows: int = 1) -> Dict[str, Any]:
        """æµ‹è¯•è¡¨å¥åº·çŠ¶æ€"""
        query = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_id}.{table_name}`"
        result = self.client.query(query).result()
        count = list(result)[0].count
        
        if count < min_rows:
            raise Exception(f"è¡¨ {table_name} æ•°æ®ä¸è¶³: {count} è¡Œ (æœ€å°‘éœ€è¦ {min_rows} è¡Œ)")
        
        return {
            "message": f"è¡¨ {table_name} å¥åº·: {count} è¡Œæ•°æ®",
            "data_count": count
        }
    
    def _test_view_integrity(self, view_name: str) -> Dict[str, Any]:
        """æµ‹è¯•è§†å›¾å®Œæ•´æ€§"""
        query = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_id}.{view_name}`"
        result = self.client.query(query).result()
        count = list(result)[0].count
        
        return {
            "message": f"è§†å›¾ {view_name} å®Œæ•´æ€§æ­£å¸¸: {count} è¡Œæ•°æ®",
            "data_count": count
        }
    
    def _test_canonical_view_integrity(self, view_name: str) -> Dict[str, Any]:
        """æµ‹è¯•æ ‡å‡†åŒ–è§†å›¾å®Œæ•´æ€§"""
        query = f"""
        SELECT 
            COUNT(*) as count,
            COUNT(DISTINCT period) as unique_periods,
            AVG(p_win) as avg_p_win
        FROM `{self.project_id}.{self.dataset_id}.{view_name}`
        """
        result = self.client.query(query).result()
        row = list(result)[0]
        
        return {
            "message": f"æ ‡å‡†åŒ–è§†å›¾ {view_name} å®Œæ•´æ€§æ­£å¸¸: {row.count} è¡Œ, {row.unique_periods} ä¸ªå”¯ä¸€æœŸæ•°",
            "data_count": row.count
        }
    
    def _test_signal_pool_integrity(self) -> Dict[str, Any]:
        """æµ‹è¯•ä¿¡å·æ± å®Œæ•´æ€§"""
        query = f"""
        SELECT 
            COUNT(*) as total_count,
            COUNT(DISTINCT period) as unique_periods,
            SUM(CASE WHEN p_win > 0.5 THEN 1 ELSE 0 END) as high_confidence_signals
        FROM `{self.project_id}.{self.dataset_id}.signal_pool_union_v3`
        """
        result = self.client.query(query).result()
        row = list(result)[0]
        
        if row.total_count == 0:
            raise Exception("ä¿¡å·æ± ä¸ºç©º")
        
        return {
            "message": f"ä¿¡å·æ± å®Œæ•´æ€§æ­£å¸¸: {row.total_count} ä¸ªä¿¡å·, {row.unique_periods} ä¸ªæœŸæ•°, {row.high_confidence_signals} ä¸ªé«˜ç½®ä¿¡åº¦ä¿¡å·",
            "data_count": row.total_count
        }
    
    def _test_decision_candidates_logic(self) -> Dict[str, Any]:
        """æµ‹è¯•å†³ç­–å€™é€‰é€»è¾‘"""
        query = f"""
        SELECT 
            COUNT(*) as total_candidates,
            COUNT(DISTINCT period) as unique_periods,
            AVG(p_win) as avg_confidence
        FROM `{self.project_id}.{self.dataset_id}.lab_push_candidates_v2`
        """
        result = self.client.query(query).result()
        row = list(result)[0]
        
        if row.total_candidates == 0:
            raise Exception("æ²¡æœ‰ç”Ÿæˆå†³ç­–å€™é€‰")
        
        return {
            "message": f"å†³ç­–å€™é€‰é€»è¾‘æ­£å¸¸: {row.total_candidates} ä¸ªå€™é€‰, {row.unique_periods} ä¸ªæœŸæ•°, å¹³å‡ç½®ä¿¡åº¦ {row.avg_confidence:.3f}",
            "data_count": row.total_candidates
        }
    
    def _test_runtime_params_logic(self) -> Dict[str, Any]:
        """æµ‹è¯•è¿è¡Œæ—¶å‚æ•°é€»è¾‘"""
        query = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_id}.runtime_params`"
        result = self.client.query(query).result()
        count = list(result)[0].count
        
        if count == 0:
            raise Exception("è¿è¡Œæ—¶å‚æ•°ä¸ºç©º")
        
        return {
            "message": f"è¿è¡Œæ—¶å‚æ•°æ­£å¸¸: {count} ä¸ªå‚æ•°",
            "data_count": count
        }
    
    def _test_data_correlation(self) -> Dict[str, Any]:
        """æµ‹è¯•æ•°æ®å…³è”æ€§"""
        query = f"""
        SELECT 
            COUNT(DISTINCT s.period) as signal_periods,
            COUNT(DISTINCT c.period) as candidate_periods,
            COUNT(DISTINCT r.market) as runtime_params
        FROM `{self.project_id}.{self.dataset_id}.signal_pool_union_v3` s
        FULL OUTER JOIN `{self.project_id}.{self.dataset_id}.lab_push_candidates_v2` c
            ON s.period = c.period
        CROSS JOIN `{self.project_id}.{self.dataset_id}.runtime_params` r
        """
        result = self.client.query(query).result()
        row = list(result)[0]
        
        return {
            "message": f"æ•°æ®å…³è”æ€§æ­£å¸¸: ä¿¡å·æœŸæ•° {row.signal_periods}, å€™é€‰æœŸæ•° {row.candidate_periods}, è¿è¡Œå‚æ•° {row.runtime_params}",
            "data_count": row.signal_periods
        }
    
    def _test_query_performance(self, table_name: str) -> Dict[str, Any]:
        """æµ‹è¯•æŸ¥è¯¢æ€§èƒ½"""
        start_time = time.time()
        query = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_id}.{table_name}`"
        result = self.client.query(query).result()
        count = list(result)[0].count
        query_time = time.time() - start_time
        
        if query_time > 10.0:  # è¶…è¿‡10ç§’è®¤ä¸ºæ€§èƒ½ä¸ä½³
            raise Exception(f"æŸ¥è¯¢æ€§èƒ½ä¸ä½³: {query_time:.2f}ç§’")
        
        return {
            "message": f"æŸ¥è¯¢æ€§èƒ½æ­£å¸¸: {table_name} æŸ¥è¯¢è€—æ—¶ {query_time:.2f}ç§’, {count} è¡Œæ•°æ®",
            "data_count": count
        }
    
    def _test_signal_pool_data_quality(self) -> Dict[str, Any]:
        """æµ‹è¯•ä¿¡å·æ± æ•°æ®è´¨é‡"""
        query = f"""
        SELECT 
            COUNT(*) as total_count,
            COUNT(CASE WHEN p_win IS NULL THEN 1 END) as null_p_win,
            COUNT(CASE WHEN p_win < 0 OR p_win > 1 THEN 1 END) as invalid_p_win,
            COUNT(CASE WHEN period IS NULL THEN 1 END) as null_period
        FROM `{self.project_id}.{self.dataset_id}.signal_pool_union_v3`
        """
        result = self.client.query(query).result()
        row = list(result)[0]
        
        quality_issues = row.null_p_win + row.invalid_p_win + row.null_period
        if quality_issues > 0:
            raise Exception(f"æ•°æ®è´¨é‡é—®é¢˜: {quality_issues} ä¸ªå¼‚å¸¸è®°å½•")
        
        return {
            "message": f"ä¿¡å·æ± æ•°æ®è´¨é‡è‰¯å¥½: {row.total_count} è¡Œæ•°æ®ï¼Œæ— è´¨é‡é—®é¢˜",
            "data_count": row.total_count
        }
    
    def _test_data_consistency(self) -> Dict[str, Any]:
        """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§"""
        # æ£€æŸ¥ä¿¡å·æ± å’Œå†³ç­–å€™é€‰çš„æœŸæ•°ä¸€è‡´æ€§
        query = f"""
        SELECT 
            COUNT(DISTINCT s.period) as signal_periods,
            COUNT(DISTINCT c.period) as candidate_periods
        FROM `{self.project_id}.{self.dataset_id}.signal_pool_union_v3` s
        FULL OUTER JOIN `{self.project_id}.{self.dataset_id}.lab_push_candidates_v2` c
            ON s.period = c.period
        """
        result = self.client.query(query).result()
        row = list(result)[0]
        
        return {
            "message": f"æ•°æ®ä¸€è‡´æ€§æ­£å¸¸: ä¿¡å·æœŸæ•° {row.signal_periods}, å€™é€‰æœŸæ•° {row.candidate_periods}",
            "data_count": row.signal_periods
        }
    
    def _test_concurrent_queries(self) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘æŸ¥è¯¢ç¨³å®šæ€§"""
        import concurrent.futures
        
        def run_query():
            query = f"SELECT COUNT(*) FROM `{self.project_id}.{self.dataset_id}.signal_pool_union_v3`"
            result = self.client.query(query).result()
            return list(result)[0][0]
        
        # å¹¶å‘æ‰§è¡Œ3ä¸ªæŸ¥è¯¢
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(run_query) for _ in range(3)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        # æ£€æŸ¥ç»“æœä¸€è‡´æ€§
        if len(set(results)) > 1:
            raise Exception(f"å¹¶å‘æŸ¥è¯¢ç»“æœä¸ä¸€è‡´: {results}")
        
        return {
            "message": f"å¹¶å‘æŸ¥è¯¢ç¨³å®šæ€§æ­£å¸¸: 3ä¸ªå¹¶å‘æŸ¥è¯¢ç»“æœä¸€è‡´ ({results[0]} è¡Œ)",
            "data_count": results[0]
        }
    
    def _generate_business_test_report(self, test_summary: Dict[str, Any]):
        """ç”Ÿæˆä¸šåŠ¡æµ‹è¯•æŠ¥å‘Š"""
        # JSONæŠ¥å‘Š
        json_path = f"/Users/a606/cloud_function_source/pc28_business_test_report_{self.timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(test_summary, f, indent=2, ensure_ascii=False)
        
        # MarkdownæŠ¥å‘Š
        md_path = f"/Users/a606/cloud_function_source/pc28_business_test_report_{self.timestamp}.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write("# PC28ç»¼åˆä¸šåŠ¡æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"**æµ‹è¯•æ—¶é—´**: {test_summary['start_time']}\n")
            f.write(f"**æ€»æµ‹è¯•æ•°**: {test_summary['total_tests']}\n")
            f.write(f"**é€šè¿‡**: {test_summary['passed_tests']}\n")
            f.write(f"**å¤±è´¥**: {test_summary['failed_tests']}\n")
            f.write(f"**è·³è¿‡**: {test_summary['skipped_tests']}\n")
            f.write(f"**æˆåŠŸç‡**: {test_summary['success_rate']:.2f}%\n")
            f.write(f"**æ€»è€—æ—¶**: {test_summary['total_duration']:.2f}ç§’\n")
            f.write(f"**ç³»ç»Ÿå¥åº·**: {'âœ… å¥åº·' if test_summary['system_health'] else 'âŒ å¼‚å¸¸'}\n\n")
            
            # æŒ‰ç±»åˆ«è¾“å‡ºæµ‹è¯•ç»“æœ
            for category in test_summary['test_categories']:
                f.write(f"## {category['category_name']}\n")
                f.write(f"**é€šè¿‡**: {category['passed']}/{category['total']}\n\n")
                
                for test in category['tests']:
                    status_icon = "âœ…" if test['status'] == 'pass' else "âŒ" if test['status'] == 'fail' else "â­ï¸"
                    f.write(f"### {status_icon} {test['test_name']}\n")
                    f.write(f"**çŠ¶æ€**: {test['status']}\n")
                    f.write(f"**æ¶ˆæ¯**: {test['message']}\n")
                    f.write(f"**è€—æ—¶**: {test['duration']:.2f}ç§’\n")
                    if test['data_count'] is not None:
                        f.write(f"**æ•°æ®è¡Œæ•°**: {test['data_count']}\n")
                    if test['error_details']:
                        f.write(f"**é”™è¯¯è¯¦æƒ…**: {test['error_details']}\n")
                    f.write("\n")
        
        logger.info(f"ğŸ“„ ä¸šåŠ¡æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜:")
        logger.info(f"  JSON: {json_path}")
        logger.info(f"  Markdown: {md_path}")

def main():
    """ä¸»å‡½æ•°"""
    tester = PC28ComprehensiveBusinessTest()
    
    print("ğŸ§ª PC28ç»¼åˆä¸šåŠ¡æµ‹è¯•ç³»ç»Ÿ")
    print("=" * 60)
    print("ğŸ¯ ç›®æ ‡ï¼šéªŒè¯ç³»ç»Ÿç¨³å®šæ€§å’Œä¸šåŠ¡åŠŸèƒ½å®Œæ•´æ€§")
    print("ğŸ“‹ æµ‹è¯•èŒƒå›´ï¼šæ•°æ®æºã€æ•°æ®æµã€ä¸šåŠ¡é€»è¾‘ã€æ€§èƒ½ã€è´¨é‡ã€ç¨³å®šæ€§")
    print("=" * 60)
    
    # è¿è¡Œç»¼åˆä¸šåŠ¡æµ‹è¯•
    results = tester.run_comprehensive_business_tests()
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦:")
    print(f"  æ€»æµ‹è¯•æ•°: {results['total_tests']}")
    print(f"  é€šè¿‡: {results['passed_tests']}")
    print(f"  å¤±è´¥: {results['failed_tests']}")
    print(f"  è·³è¿‡: {results['skipped_tests']}")
    print(f"  æˆåŠŸç‡: {results['success_rate']:.2f}%")
    print(f"  æ€»è€—æ—¶: {results['total_duration']:.2f}ç§’")
    
    print(f"\nğŸ“ˆ æµ‹è¯•ç±»åˆ«:")
    for category in results['test_categories']:
        success_rate = (category['passed'] / category['total'] * 100) if category['total'] > 0 else 0
        print(f"  {category['category_name']}: {category['passed']}/{category['total']} ({success_rate:.1f}%)")
    
    if results['system_health']:
        print(f"\nğŸ‰ ç³»ç»Ÿå¥åº·çŠ¶æ€: âœ… å¥åº·")
        print(f"ğŸ’¡ æ‰€æœ‰æ ¸å¿ƒä¸šåŠ¡åŠŸèƒ½æ­£å¸¸è¿è¡Œ")
        print(f"ğŸ”¥ ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿›è¡Œå®‰å…¨ä¼˜åŒ–")
    else:
        print(f"\nâš ï¸ ç³»ç»Ÿå¥åº·çŠ¶æ€: âŒ å¼‚å¸¸")
        print(f"ğŸ”§ è¯·å…ˆè§£å†³å¤±è´¥çš„æµ‹è¯•é¡¹ç›®")
        
        # æ˜¾ç¤ºå¤±è´¥çš„æµ‹è¯•
        failed_tests = [r for r in results['test_results'] if r['status'] == 'fail']
        if failed_tests:
            print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
            for test in failed_tests:
                print(f"  - {test['test_name']}: {test['message']}")
    
    return results

if __name__ == "__main__":
    main()