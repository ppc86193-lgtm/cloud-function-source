#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PC28ç»ˆæä¿®å¤ç³»ç»Ÿ
ä¸€é”®è§£å†³æ‰€æœ‰å·²è¯†åˆ«çš„é—®é¢˜ï¼šå­—æ®µä¸åŒ¹é…ã€æ•°æ®æµä¸­æ–­ã€è§†å›¾å®šä¹‰é”™è¯¯ç­‰
"""

import os
import json
import subprocess
import shlex
import datetime
import logging
from typing import Dict, List, Any, Optional, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PC28UltimateRepairSystem:
    """PC28ç»ˆæä¿®å¤ç³»ç»Ÿ"""
    
    def __init__(self, project_id: str = "wprojectl", dataset_lab: str = "pc28_lab"):
        self.project_id = project_id
        self.dataset_lab = dataset_lab
        self.timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å®Œæ•´çš„ä¿®å¤æ–¹æ¡ˆ
        self.repair_plan = {
            "phase_1_foundation": {
                "description": "åŸºç¡€è¡¨ç»“æ„ä¿®å¤",
                "repairs": [
                    {
                        "name": "p_cloud_clean_merged_dedup_v",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.p_cloud_clean_merged_dedup_v` AS
                        SELECT 
                            period, 
                            ts_utc, 
                            p_even, 
                            src,
                            999 as n_src
                        FROM (
                            SELECT *, ROW_NUMBER() OVER (PARTITION BY period ORDER BY ts_utc DESC) rn
                            FROM `{project}.{dataset}.cloud_pred_today_norm`
                        ) WHERE rn=1
                        """
                    },
                    {
                        "name": "p_map_clean_merged_dedup_v",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.p_map_clean_merged_dedup_v` AS
                        SELECT 
                            period,
                            ts_utc,
                            p_even,
                            'map' as src,
                            1 as n_src
                        FROM `{project}.{dataset}.cloud_pred_today_norm`
                        WHERE period IS NOT NULL
                        """
                    },
                    {
                        "name": "p_size_clean_merged_dedup_v",
                        "type": "view_recreation", 
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.p_size_clean_merged_dedup_v` AS
                        SELECT 
                            period,
                            ts_utc,
                            p_even,
                            'size' as src,
                            1 as n_src
                        FROM `{project}.{dataset}.cloud_pred_today_norm`
                        WHERE period IS NOT NULL
                        """
                    }
                ]
            },
            "phase_2_prediction_views": {
                "description": "é¢„æµ‹è§†å›¾å±‚ä¿®å¤",
                "repairs": [
                    {
                        "name": "p_cloud_today_v",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.p_cloud_today_v` AS
                        WITH params AS (
                            SELECT MAX(DATE(ts_utc,'Asia/Shanghai')) AS day_id
                            FROM `{project}.{dataset}.p_cloud_clean_merged_dedup_v`
                        )
                        SELECT 
                            period, 
                            ts_utc,
                            GREATEST(LEAST(CAST(p_even AS FLOAT64), 1-1e-6), 1e-6) AS p_even,
                            'cloud' AS src,
                            999 AS n_src
                        FROM `{project}.{dataset}.p_cloud_clean_merged_dedup_v`, params
                        WHERE DATE(ts_utc,'Asia/Shanghai')=params.day_id
                        """
                    },
                    {
                        "name": "p_map_today_v",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.p_map_today_v` AS
                        SELECT 
                            period, 
                            ts_utc, 
                            p_even, 
                            src, 
                            n_src 
                        FROM `{project}.{dataset}.p_map_clean_merged_dedup_v` 
                        WHERE DATE(ts_utc, 'Asia/Shanghai') >= DATE_SUB(CURRENT_DATE('Asia/Shanghai'), INTERVAL 7 DAY) 
                        ORDER BY ts_utc DESC
                        """
                    },
                    {
                        "name": "p_size_today_v",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.p_size_today_v` AS
                        SELECT 
                            period, 
                            ts_utc as timestamp, 
                            p_even, 
                            src, 
                            n_src 
                        FROM `{project}.{dataset}.p_size_clean_merged_dedup_v` 
                        WHERE DATE(ts_utc, 'Asia/Shanghai') >= DATE_SUB(CURRENT_DATE('Asia/Shanghai'), INTERVAL 7 DAY) 
                        ORDER BY ts_utc DESC
                        """
                    }
                ]
            },
            "phase_3_canonical_views": {
                "description": "æ ‡å‡†åŒ–è§†å›¾å±‚ä¿®å¤",
                "repairs": [
                    {
                        "name": "p_map_today_canon_v",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.p_map_today_canon_v` AS
                        SELECT 
                            CONCAT(CAST(period AS STRING), '_', CURRENT_DATE('Asia/Shanghai')) as draw_id,
                            ts_utc,
                            period,
                            'map' as market,
                            CASE WHEN p_even > 0.5 THEN 'even' ELSE 'odd' END as pick,
                            p_even as p_win,
                            'map' as source,
                            GREATEST(LEAST(p_even, 0.99), 0.01) as vote_ratio,
                            CASE WHEN p_even > 0.5 THEN 'å¶æ•°' ELSE 'å¥‡æ•°' END as pick_zh,
                            CURRENT_DATE('Asia/Shanghai') as day_id_cst
                        FROM `{project}.{dataset}.p_map_today_v`
                        WHERE p_even IS NOT NULL 
                          AND p_even BETWEEN 0.01 AND 0.99
                        """
                    },
                    {
                        "name": "p_size_today_canon_v",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.p_size_today_canon_v` AS
                        SELECT 
                            CONCAT(CAST(period AS STRING), '_', CURRENT_DATE('Asia/Shanghai')) as draw_id,
                            timestamp as ts_utc,
                            period,
                            'size' as market,
                            CASE WHEN p_even > 0.5 THEN 'big' ELSE 'small' END as pick,
                            p_even as p_win,
                            'size' as source,
                            GREATEST(LEAST(p_even, 0.99), 0.01) as vote_ratio,
                            CASE WHEN p_even > 0.5 THEN 'å¤§' ELSE 'å°' END as pick_zh,
                            CURRENT_DATE('Asia/Shanghai') as day_id_cst
                        FROM `{project}.{dataset}.p_size_today_v`
                        WHERE p_even IS NOT NULL 
                          AND p_even BETWEEN 0.01 AND 0.99
                        """
                    }
                ]
            },
            "phase_4_signal_pool": {
                "description": "ä¿¡å·æ± ä¿®å¤",
                "repairs": [
                    {
                        "name": "signal_pool_union_v3",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.signal_pool_union_v3` AS
                        SELECT 
                            CONCAT(draw_id, '_', market, '_', pick) as id,
                            draw_id,
                            ts_utc,
                            period,
                            market,
                            pick,
                            p_win,
                            source,
                            vote_ratio,
                            pick_zh,
                            day_id_cst,
                            CURRENT_TIMESTAMP() as created_at
                        FROM (
                            SELECT * FROM `{project}.{dataset}.p_map_today_canon_v`
                            
                            UNION ALL
                            
                            SELECT * FROM `{project}.{dataset}.p_size_today_canon_v`
                        ) combined
                        WHERE p_win IS NOT NULL
                          AND vote_ratio > 0.1
                        ORDER BY draw_id, market, p_win DESC
                        """
                    }
                ]
            },
            "phase_5_decision_layer": {
                "description": "å†³ç­–å±‚ä¿®å¤",
                "repairs": [
                    {
                        "name": "lab_push_candidates_v2",
                        "type": "view_recreation",
                        "sql": """
                        CREATE OR REPLACE VIEW `{project}.{dataset}.lab_push_candidates_v2` AS
                        WITH signal_with_params AS (
                            SELECT 
                                s.*,
                                p.ev_min,
                                p.p_min_base,
                                p.max_kelly,
                                p.target_acc,
                                p.target_cov
                            FROM `{project}.{dataset}.signal_pool_union_v3` s
                            JOIN `{project}.{dataset}.runtime_params` p ON s.market = p.market
                        ),
                        candidates AS (
                            SELECT 
                                CONCAT(draw_id, '_', market, '_', pick) as id,
                                CURRENT_TIMESTAMP() as created_at,
                                ts_utc,
                                period,
                                market,
                                pick,
                                p_win,
                                -- è®¡ç®—EV
                                CASE 
                                    WHEN pick IN ('even', 'big') THEN (p_win * 2.0 - 1.0)
                                    WHEN pick IN ('odd', 'small') THEN ((1-p_win) * 2.0 - 1.0)
                                    ELSE 0
                                END as ev,
                                -- è®¡ç®—Kellyåˆ†æ•°
                                CASE 
                                    WHEN pick IN ('even', 'big') THEN 
                                        LEAST(GREATEST((p_win * 2.0 - 1.0) / 1.0, 0), max_kelly)
                                    WHEN pick IN ('odd', 'small') THEN 
                                        LEAST(GREATEST(((1-p_win) * 2.0 - 1.0) / 1.0, 0), max_kelly)
                                    ELSE 0
                                END as kelly_frac,
                                source,
                                vote_ratio,
                                pick_zh,
                                day_id_cst,
                                draw_id
                            FROM signal_with_params
                            WHERE p_win >= p_min_base
                        )
                        SELECT *
                        FROM candidates
                        WHERE ev > 0.001  -- åªä¿ç•™æ­£EVçš„å€™é€‰
                          AND kelly_frac > 0
                        ORDER BY ev DESC, kelly_frac DESC
                        """
                    }
                ]
            }
        }

    def _run_bq_command(self, sql: str) -> Tuple[bool, str]:
        """æ‰§è¡ŒBigQueryå‘½ä»¤"""
        try:
            cmd = f"bq query --use_legacy_sql=false --format=json " + shlex.quote(sql)
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                return True, result.stdout.strip()
            else:
                return False, result.stderr.strip()
                
        except subprocess.TimeoutExpired:
            return False, "æŸ¥è¯¢è¶…æ—¶"
        except Exception as e:
            return False, f"æ‰§è¡Œå¼‚å¸¸: {e}"

    def execute_repair_phase(self, phase_name: str, phase_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œä¿®å¤é˜¶æ®µ"""
        logger.info(f"ğŸ”§ æ‰§è¡Œä¿®å¤é˜¶æ®µ: {phase_config['description']}")
        
        phase_results = {
            "phase_name": phase_name,
            "description": phase_config["description"],
            "repairs_attempted": [],
            "repairs_successful": [],
            "repairs_failed": [],
            "phase_success": False
        }
        
        for repair in phase_config["repairs"]:
            repair_name = repair["name"]
            logger.info(f"  ä¿®å¤: {repair_name}")
            phase_results["repairs_attempted"].append(repair_name)
            
            # æ ¼å¼åŒ–SQL
            formatted_sql = repair["sql"].format(
                project=self.project_id,
                dataset=self.dataset_lab
            )
            
            # æ‰§è¡Œä¿®å¤
            success, result = self._run_bq_command(formatted_sql)
            
            if success:
                phase_results["repairs_successful"].append(repair_name)
                logger.info(f"    âœ… {repair_name} ä¿®å¤æˆåŠŸ")
            else:
                phase_results["repairs_failed"].append({
                    "name": repair_name,
                    "error": result
                })
                logger.error(f"    âŒ {repair_name} ä¿®å¤å¤±è´¥: {result}")
        
        phase_results["phase_success"] = (
            len(phase_results["repairs_successful"]) > 0 and 
            len(phase_results["repairs_failed"]) == 0
        )
        
        return phase_results

    def verify_system_health(self) -> Dict[str, Any]:
        """éªŒè¯ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        logger.info("ğŸ” éªŒè¯ç³»ç»Ÿå¥åº·çŠ¶æ€...")
        
        health_check = {
            "timestamp": datetime.datetime.now().isoformat(),
            "table_status": {},
            "data_flow_status": {},
            "overall_health": False
        }
        
        # æ£€æŸ¥å…³é”®è¡¨
        key_tables = [
            "cloud_pred_today_norm",
            "p_cloud_clean_merged_dedup_v", 
            "p_map_clean_merged_dedup_v",
            "p_size_clean_merged_dedup_v",
            "p_cloud_today_v",
            "p_map_today_v", 
            "p_size_today_v",
            "p_map_today_canon_v",
            "p_size_today_canon_v",
            "signal_pool_union_v3",
            "lab_push_candidates_v2",
            "runtime_params"
        ]
        
        for table in key_tables:
            health_check["table_status"][table] = self._check_table_health(table)
        
        # æ£€æŸ¥æ•°æ®æµ
        health_check["data_flow_status"] = self._check_data_flow()
        
        # è®¡ç®—æ•´ä½“å¥åº·çŠ¶æ€
        healthy_tables = sum(1 for status in health_check["table_status"].values() if status["healthy"])
        total_tables = len(health_check["table_status"])
        
        health_check["overall_health"] = (
            healthy_tables >= total_tables * 0.8 and  # 80%çš„è¡¨å¥åº·
            health_check["data_flow_status"]["signal_pool_count"] > 0 and
            health_check["data_flow_status"]["candidates_count"] > 0
        )
        
        logger.info(f"ç³»ç»Ÿå¥åº·çŠ¶æ€: {healthy_tables}/{total_tables} è¡¨å¥åº·")
        
        return health_check

    def _check_table_health(self, table_name: str) -> Dict[str, Any]:
        """æ£€æŸ¥è¡¨å¥åº·çŠ¶æ€"""
        status = {
            "table_name": table_name,
            "healthy": False,
            "row_count": 0,
            "accessible": False,
            "error": None
        }
        
        try:
            sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.{table_name}`"
            success, result = self._run_bq_command(sql)
            
            if success:
                data = json.loads(result)
                status["row_count"] = int(data[0]["count"])
                status["accessible"] = True
                status["healthy"] = status["row_count"] >= 0  # å¯è®¿é—®å³ä¸ºå¥åº·
            else:
                status["error"] = result
                
        except Exception as e:
            status["error"] = str(e)
        
        return status

    def _check_data_flow(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®æµçŠ¶æ€"""
        flow_status = {
            "signal_pool_count": 0,
            "candidates_count": 0,
            "runtime_params_count": 0,
            "data_flow_healthy": False
        }
        
        try:
            # æ£€æŸ¥ä¿¡å·æ± 
            sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3`"
            success, result = self._run_bq_command(sql)
            if success:
                data = json.loads(result)
                flow_status["signal_pool_count"] = int(data[0]["count"])
            
            # æ£€æŸ¥å†³ç­–å€™é€‰
            sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.lab_push_candidates_v2`"
            success, result = self._run_bq_command(sql)
            if success:
                data = json.loads(result)
                flow_status["candidates_count"] = int(data[0]["count"])
            
            # æ£€æŸ¥è¿è¡Œå‚æ•°
            sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.runtime_params`"
            success, result = self._run_bq_command(sql)
            if success:
                data = json.loads(result)
                flow_status["runtime_params_count"] = int(data[0]["count"])
            
            flow_status["data_flow_healthy"] = (
                flow_status["signal_pool_count"] > 0 and
                flow_status["candidates_count"] > 0 and
                flow_status["runtime_params_count"] > 0
            )
            
        except Exception as e:
            logger.error(f"æ•°æ®æµæ£€æŸ¥å¤±è´¥: {e}")
        
        return flow_status

    def run_ultimate_repair(self) -> Dict[str, Any]:
        """è¿è¡Œç»ˆæä¿®å¤"""
        logger.info("ğŸš€ å¯åŠ¨PC28ç»ˆæä¿®å¤ç³»ç»Ÿ...")
        
        repair_results = {
            "repair_timestamp": self.timestamp,
            "phase_results": {},
            "final_health_check": {},
            "overall_success": False,
            "summary": {}
        }
        
        # æŒ‰é˜¶æ®µæ‰§è¡Œä¿®å¤
        phase_order = [
            "phase_1_foundation",
            "phase_2_prediction_views", 
            "phase_3_canonical_views",
            "phase_4_signal_pool",
            "phase_5_decision_layer"
        ]
        
        successful_phases = 0
        total_repairs_successful = 0
        total_repairs_attempted = 0
        
        for phase_name in phase_order:
            if phase_name in self.repair_plan:
                phase_config = self.repair_plan[phase_name]
                phase_result = self.execute_repair_phase(phase_name, phase_config)
                repair_results["phase_results"][phase_name] = phase_result
                
                if phase_result["phase_success"]:
                    successful_phases += 1
                
                total_repairs_attempted += len(phase_result["repairs_attempted"])
                total_repairs_successful += len(phase_result["repairs_successful"])
        
        # æœ€ç»ˆå¥åº·æ£€æŸ¥
        repair_results["final_health_check"] = self.verify_system_health()
        
        # è®¡ç®—æ•´ä½“æˆåŠŸç‡
        repair_results["overall_success"] = (
            successful_phases >= len(phase_order) * 0.8 and  # 80%é˜¶æ®µæˆåŠŸ
            repair_results["final_health_check"]["overall_health"]
        )
        
        # ç”Ÿæˆæ‘˜è¦
        repair_results["summary"] = {
            "total_phases": len(phase_order),
            "successful_phases": successful_phases,
            "total_repairs_attempted": total_repairs_attempted,
            "total_repairs_successful": total_repairs_successful,
            "success_rate": total_repairs_successful / total_repairs_attempted if total_repairs_attempted > 0 else 0,
            "final_signal_pool_count": repair_results["final_health_check"]["data_flow_status"]["signal_pool_count"],
            "final_candidates_count": repair_results["final_health_check"]["data_flow_status"]["candidates_count"]
        }
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_ultimate_report(repair_results)
        
        return repair_results

    def _generate_ultimate_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆç»ˆæä¿®å¤æŠ¥å‘Š"""
        report_path = f"/Users/a606/cloud_function_source/pc28_ultimate_repair_report_{self.timestamp}.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“Š ç»ˆæä¿®å¤æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    repair_system = PC28UltimateRepairSystem()
    
    print("ğŸš€ PC28ç»ˆæä¿®å¤ç³»ç»Ÿå¯åŠ¨")
    print("=" * 60)
    print("ğŸ¯ ç›®æ ‡ï¼šä¸€é”®è§£å†³æ‰€æœ‰å·²è¯†åˆ«çš„ç³»ç»Ÿé—®é¢˜")
    print("ğŸ“‹ ä¿®å¤èŒƒå›´ï¼šå­—æ®µä¸åŒ¹é…ã€æ•°æ®æµä¸­æ–­ã€è§†å›¾å®šä¹‰é”™è¯¯")
    print("=" * 60)
    
    # è¿è¡Œç»ˆæä¿®å¤
    results = repair_system.run_ultimate_repair()
    
    # è¾“å‡ºç»“æœ
    summary = results["summary"]
    health = results["final_health_check"]
    
    print(f"\nğŸ“Š ä¿®å¤ç»“æœæ‘˜è¦:")
    print(f"  ä¿®å¤é˜¶æ®µ: {summary['successful_phases']}/{summary['total_phases']} æˆåŠŸ")
    print(f"  ä¿®å¤é¡¹ç›®: {summary['total_repairs_successful']}/{summary['total_repairs_attempted']} æˆåŠŸ")
    print(f"  æˆåŠŸç‡: {summary['success_rate']:.1%}")
    print(f"  æ•´ä½“æˆåŠŸ: {results['overall_success']}")
    
    print(f"\nğŸ“ˆ ç³»ç»ŸçŠ¶æ€:")
    print(f"  ç³»ç»Ÿå¥åº·: {health['overall_health']}")
    print(f"  ä¿¡å·æ± æ•°æ®: {summary['final_signal_pool_count']} è¡Œ")
    print(f"  å†³ç­–å€™é€‰: {summary['final_candidates_count']} è¡Œ")
    
    if results["overall_success"]:
        print(f"\nğŸ‰ ç»ˆæä¿®å¤å®Œæˆï¼")
        print(f"ğŸ’¡ PC28ç³»ç»Ÿå·²å®Œå…¨æ¢å¤ï¼Œæ‰€æœ‰æ•°æ®æµæ­£å¸¸è¿è¡Œ")
        print(f"ğŸ”¥ æ ¸å¿ƒä¸šåŠ¡é€»è¾‘å·²ä¿®å¤ï¼Œå¯ä»¥æ­£å¸¸ç”Ÿæˆäº¤æ˜“å†³ç­–")
    else:
        print(f"\nâš ï¸ ä¿®å¤æœªå®Œå…¨æˆåŠŸ")
        
        # æ˜¾ç¤ºå¤±è´¥çš„é˜¶æ®µ
        failed_phases = []
        for phase_name, phase_result in results["phase_results"].items():
            if not phase_result["phase_success"]:
                failed_phases.append(phase_name)
        
        if failed_phases:
            print(f"  å¤±è´¥é˜¶æ®µ: {', '.join(failed_phases)}")
        
        if summary['final_signal_pool_count'] == 0:
            print(f"  å»ºè®®: æ£€æŸ¥ä¸Šæ¸¸æ•°æ®æºï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„é¢„æµ‹æ•°æ®")
        elif summary['final_candidates_count'] == 0:
            print(f"  å»ºè®®: æ£€æŸ¥å†³ç­–é€»è¾‘å‚æ•°ï¼Œå¯èƒ½è¿‡æ»¤æ¡ä»¶è¿‡äºä¸¥æ ¼")

if __name__ == "__main__":
    main()