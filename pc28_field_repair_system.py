#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PC28å­—æ®µä¿®å¤ç³»ç»Ÿ
ä¸“é—¨ä¿®å¤å­—æ®µåç§°ä¸åŒ¹é…å’Œè§†å›¾å®šä¹‰é”™è¯¯çš„é—®é¢˜
"""

import os
import json
import subprocess
import shlex
import datetime
import logging
from typing import Dict, List, Any, Optional, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PC28FieldRepairSystem:
    """PC28å­—æ®µä¿®å¤ç³»ç»Ÿ"""
    
    def __init__(self, project_id: str = "wprojectl", dataset_lab: str = "pc28_lab"):
        self.project_id = project_id
        self.dataset_lab = dataset_lab
        self.timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å­—æ®µæ˜ å°„ä¿®å¤è§„åˆ™
        self.field_repairs = {
            "p_cloud_clean_merged_dedup_v": {
                "current_fields": ["period", "ts_utc", "p_even", "src"],
                "expected_fields": ["period", "ts_utc", "p_even", "src", "n_src"],
                "missing_fields": ["n_src"],
                "repair_sql": """
                CREATE OR REPLACE VIEW `{project}.{dataset}.p_cloud_clean_merged_dedup_v` AS
                SELECT 
                    period, 
                    ts_utc, 
                    p_even, 
                    src,
                    999 as n_src  -- æ·»åŠ ç¼ºå¤±çš„n_srcå­—æ®µ
                FROM (
                    SELECT *, ROW_NUMBER() OVER (PARTITION BY period ORDER BY ts_utc DESC) rn
                    FROM `{project}.{dataset}.cloud_pred_today_norm`
                ) WHERE rn=1
                """
            },
            "p_map_clean_merged_dedup_v": {
                "current_fields": [],
                "expected_fields": ["period", "ts_utc", "p_even", "src", "n_src"],
                "missing_fields": ["period", "ts_utc", "p_even", "src", "n_src"],
                "repair_sql": """
                CREATE OR REPLACE VIEW `{project}.{dataset}.p_map_clean_merged_dedup_v` AS
                SELECT 
                    period,
                    ts_utc,
                    p_even,
                    'map' as src,
                    1 as n_src
                FROM `{project}.{dataset}.cloud_pred_today_norm`
                WHERE src = 'map' OR period IS NOT NULL
                """
            },
            "p_size_clean_merged_dedup_v": {
                "current_fields": [],
                "expected_fields": ["period", "ts_utc", "p_even", "src", "n_src"],
                "missing_fields": ["period", "ts_utc", "p_even", "src", "n_src"],
                "repair_sql": """
                CREATE OR REPLACE VIEW `{project}.{dataset}.p_size_clean_merged_dedup_v` AS
                SELECT 
                    period,
                    ts_utc,
                    p_even,
                    'size' as src,
                    1 as n_src
                FROM `{project}.{dataset}.cloud_pred_today_norm`
                WHERE src = 'size' OR period IS NOT NULL
                """
            }
        }

    def _run_bq_command(self, sql: str) -> Tuple[bool, str]:
        """æ‰§è¡ŒBigQueryå‘½ä»¤"""
        try:
            cmd = f"bq query --use_legacy_sql=false --format=json " + shlex.quote(sql)
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                return True, result.stdout.strip()
            else:
                return False, result.stderr.strip()
                
        except subprocess.TimeoutExpired:
            return False, "æŸ¥è¯¢è¶…æ—¶"
        except Exception as e:
            return False, f"æ‰§è¡Œå¼‚å¸¸: {e}"

    def diagnose_field_issues(self) -> Dict[str, Any]:
        """è¯Šæ–­å­—æ®µé—®é¢˜"""
        logger.info("ğŸ” å¼€å§‹è¯Šæ–­å­—æ®µé—®é¢˜...")
        
        diagnosis = {
            "timestamp": self.timestamp,
            "table_issues": {},
            "repair_needed": False,
            "critical_issues": []
        }
        
        for table_name, repair_info in self.field_repairs.items():
            logger.info(f"æ£€æŸ¥è¡¨: {table_name}")
            
            # æ£€æŸ¥è¡¨ç»“æ„
            table_info = self._check_table_structure(table_name)
            diagnosis["table_issues"][table_name] = table_info
            
            if table_info["needs_repair"]:
                diagnosis["repair_needed"] = True
                if table_info["severity"] == "critical":
                    diagnosis["critical_issues"].append(table_name)
        
        return diagnosis

    def _check_table_structure(self, table_name: str) -> Dict[str, Any]:
        """æ£€æŸ¥è¡¨ç»“æ„"""
        table_info = {
            "table_name": table_name,
            "exists": False,
            "current_fields": [],
            "missing_fields": [],
            "needs_repair": False,
            "severity": "normal",
            "error": None
        }
        
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨å¹¶è·å–ç»“æ„
            cmd = f"bq show --format=json {self.project_id}:{self.dataset_lab}.{table_name}"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                table_info["exists"] = True
                table_data = json.loads(result.stdout)
                
                # æå–å­—æ®µä¿¡æ¯
                if "schema" in table_data and "fields" in table_data["schema"]:
                    table_info["current_fields"] = [field["name"] for field in table_data["schema"]["fields"]]
                
                # æ£€æŸ¥ç¼ºå¤±å­—æ®µ
                expected_fields = self.field_repairs[table_name]["expected_fields"]
                table_info["missing_fields"] = [
                    field for field in expected_fields 
                    if field not in table_info["current_fields"]
                ]
                
                # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®å¤
                if table_info["missing_fields"]:
                    table_info["needs_repair"] = True
                    table_info["severity"] = "high" if len(table_info["missing_fields"]) > 2 else "medium"
                
                logger.info(f"  âœ… {table_name}: {len(table_info['current_fields'])} å­—æ®µ, ç¼ºå¤± {len(table_info['missing_fields'])} å­—æ®µ")
                
            else:
                table_info["error"] = result.stderr.strip()
                table_info["needs_repair"] = True
                table_info["severity"] = "critical"
                logger.error(f"  âŒ {table_name}: {table_info['error']}")
                
        except Exception as e:
            table_info["error"] = str(e)
            table_info["needs_repair"] = True
            table_info["severity"] = "critical"
            logger.error(f"  âŒ {table_name}: æ£€æŸ¥å¼‚å¸¸ - {e}")
        
        return table_info

    def repair_field_issues(self, diagnosis: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤å­—æ®µé—®é¢˜"""
        logger.info("ğŸ”§ å¼€å§‹ä¿®å¤å­—æ®µé—®é¢˜...")
        
        repair_results = {
            "timestamp": datetime.datetime.now().isoformat(),
            "repairs_attempted": [],
            "repairs_successful": [],
            "repairs_failed": [],
            "overall_success": False
        }
        
        for table_name, table_info in diagnosis["table_issues"].items():
            if table_info["needs_repair"]:
                logger.info(f"ä¿®å¤è¡¨: {table_name}")
                repair_results["repairs_attempted"].append(table_name)
                
                # è·å–ä¿®å¤SQL
                repair_sql = self.field_repairs[table_name]["repair_sql"].format(
                    project=self.project_id,
                    dataset=self.dataset_lab
                )
                
                # æ‰§è¡Œä¿®å¤
                success, result = self._run_bq_command(repair_sql)
                
                if success:
                    repair_results["repairs_successful"].append(table_name)
                    logger.info(f"  âœ… {table_name} ä¿®å¤æˆåŠŸ")
                else:
                    repair_results["repairs_failed"].append({
                        "table": table_name,
                        "error": result
                    })
                    logger.error(f"  âŒ {table_name} ä¿®å¤å¤±è´¥: {result}")
        
        repair_results["overall_success"] = (
            len(repair_results["repairs_successful"]) > 0 and 
            len(repair_results["repairs_failed"]) == 0
        )
        
        return repair_results

    def verify_repairs(self) -> Dict[str, Any]:
        """éªŒè¯ä¿®å¤æ•ˆæœ"""
        logger.info("ğŸ” éªŒè¯ä¿®å¤æ•ˆæœ...")
        
        verification = {
            "timestamp": datetime.datetime.now().isoformat(),
            "table_status": {},
            "data_flow_test": {},
            "overall_health": False
        }
        
        # 1. éªŒè¯è¡¨ç»“æ„
        for table_name in self.field_repairs.keys():
            table_status = self._verify_table_structure(table_name)
            verification["table_status"][table_name] = table_status
        
        # 2. æµ‹è¯•æ•°æ®æµ
        verification["data_flow_test"] = self._test_data_flow()
        
        # 3. æ•´ä½“å¥åº·çŠ¶æ€
        all_tables_healthy = all(
            status["healthy"] for status in verification["table_status"].values()
        )
        data_flow_healthy = verification["data_flow_test"]["signal_pool_accessible"]
        
        verification["overall_health"] = all_tables_healthy and data_flow_healthy
        
        return verification

    def _verify_table_structure(self, table_name: str) -> Dict[str, Any]:
        """éªŒè¯è¡¨ç»“æ„"""
        status = {
            "table_name": table_name,
            "healthy": False,
            "field_count": 0,
            "missing_fields": [],
            "data_count": 0
        }
        
        try:
            # æ£€æŸ¥å­—æ®µç»“æ„
            cmd = f"bq show --format=json {self.project_id}:{self.dataset_lab}.{table_name}"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                table_data = json.loads(result.stdout)
                if "schema" in table_data and "fields" in table_data["schema"]:
                    current_fields = [field["name"] for field in table_data["schema"]["fields"]]
                    status["field_count"] = len(current_fields)
                    
                    expected_fields = self.field_repairs[table_name]["expected_fields"]
                    status["missing_fields"] = [
                        field for field in expected_fields 
                        if field not in current_fields
                    ]
                    
                    status["healthy"] = len(status["missing_fields"]) == 0
            
            # æ£€æŸ¥æ•°æ®é‡
            sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.{table_name}`"
            success, result = self._run_bq_command(sql)
            if success:
                data = json.loads(result)
                status["data_count"] = int(data[0]["count"])
                
        except Exception as e:
            logger.error(f"éªŒè¯ {table_name} å¤±è´¥: {e}")
        
        return status

    def _test_data_flow(self) -> Dict[str, Any]:
        """æµ‹è¯•æ•°æ®æµ"""
        flow_test = {
            "signal_pool_accessible": False,
            "signal_pool_count": 0,
            "lab_candidates_accessible": False,
            "lab_candidates_count": 0
        }
        
        try:
            # æµ‹è¯•signal_pool_union_v3
            sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3`"
            success, result = self._run_bq_command(sql)
            if success:
                data = json.loads(result)
                flow_test["signal_pool_count"] = int(data[0]["count"])
                flow_test["signal_pool_accessible"] = True
                logger.info(f"signal_pool_union_v3: {flow_test['signal_pool_count']} è¡Œ")
            
            # æµ‹è¯•lab_push_candidates_v2
            sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.lab_push_candidates_v2`"
            success, result = self._run_bq_command(sql)
            if success:
                data = json.loads(result)
                flow_test["lab_candidates_count"] = int(data[0]["count"])
                flow_test["lab_candidates_accessible"] = True
                logger.info(f"lab_push_candidates_v2: {flow_test['lab_candidates_count']} è¡Œ")
                
        except Exception as e:
            logger.error(f"æ•°æ®æµæµ‹è¯•å¤±è´¥: {e}")
        
        return flow_test

    def run_complete_repair(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´ä¿®å¤æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´å­—æ®µä¿®å¤...")
        
        complete_results = {
            "repair_timestamp": self.timestamp,
            "diagnosis": {},
            "repair_results": {},
            "verification": {},
            "overall_success": False
        }
        
        # 1. è¯Šæ–­é—®é¢˜
        complete_results["diagnosis"] = self.diagnose_field_issues()
        
        # 2. æ‰§è¡Œä¿®å¤
        if complete_results["diagnosis"]["repair_needed"]:
            complete_results["repair_results"] = self.repair_field_issues(complete_results["diagnosis"])
        
        # 3. éªŒè¯ä¿®å¤
        complete_results["verification"] = self.verify_repairs()
        complete_results["overall_success"] = complete_results["verification"]["overall_health"]
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        self._generate_repair_report(complete_results)
        
        return complete_results

    def _generate_repair_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        report_path = f"/Users/a606/cloud_function_source/pc28_field_repair_report_{self.timestamp}.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“Š å­—æ®µä¿®å¤æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    repair_system = PC28FieldRepairSystem()
    
    print("ğŸ”§ PC28å­—æ®µä¿®å¤ç³»ç»Ÿå¯åŠ¨")
    print("=" * 50)
    
    # è¿è¡Œå®Œæ•´ä¿®å¤
    results = repair_system.run_complete_repair()
    
    # è¾“å‡ºç»“æœ
    print(f"\nğŸ“Š ä¿®å¤ç»“æœ:")
    print(f"  éœ€è¦ä¿®å¤: {results['diagnosis']['repair_needed']}")
    
    if results["diagnosis"]["repair_needed"]:
        repair_results = results.get("repair_results", {})
        print(f"  ä¿®å¤å°è¯•: {len(repair_results.get('repairs_attempted', []))}")
        print(f"  ä¿®å¤æˆåŠŸ: {len(repair_results.get('repairs_successful', []))}")
        print(f"  ä¿®å¤å¤±è´¥: {len(repair_results.get('repairs_failed', []))}")
    
    verification = results.get("verification", {})
    print(f"  æ•´ä½“å¥åº·: {verification.get('overall_health', False)}")
    
    if verification.get("data_flow_test"):
        flow_test = verification["data_flow_test"]
        print(f"  ä¿¡å·æ± æ•°æ®: {flow_test.get('signal_pool_count', 0)} è¡Œ")
        print(f"  å†³ç­–å€™é€‰: {flow_test.get('lab_candidates_count', 0)} è¡Œ")
    
    if results["overall_success"]:
        print(f"\nğŸ‰ å­—æ®µä¿®å¤å®Œæˆï¼")
        print(f"ğŸ’¡ æ‰€æœ‰è¡¨ç»“æ„å·²ä¿®å¤ï¼Œæ•°æ®æµæ¢å¤æ­£å¸¸")
    else:
        print(f"\nâš ï¸ ä¿®å¤æœªå®Œå…¨æˆåŠŸï¼Œéœ€è¦è¿›ä¸€æ­¥å¤„ç†")
        
        # æ˜¾ç¤ºå…³é”®é—®é¢˜
        if results["diagnosis"]["critical_issues"]:
            print(f"  å…³é”®é—®é¢˜è¡¨: {', '.join(results['diagnosis']['critical_issues'])}")

if __name__ == "__main__":
    main()