#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PC28 lab_push_candidates_v2 ä¿®å¤å™¨
ä¸“é—¨ä¿®å¤æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼šlab_push_candidates_v2æ— æ•°æ®é—®é¢˜
åŸºäºç°æœ‰çš„signal_pool_union_v3å’Œruntime_paramsæ•°æ®
"""
import os
import json
import subprocess
import shlex
import datetime
import logging
from typing import Dict, List, Any, Optional, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PC28LabPushCandidatesFixer:
    """PC28 lab_push_candidates_v2 ä¿®å¤å™¨"""
    
    def __init__(self, project_id: str = "wprojectl", dataset_lab: str = "pc28_lab"):
        self.project_id = project_id
        self.dataset_lab = dataset_lab
        self.timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def _run_bq_command(self, sql: str, timeout: int = 300) -> Tuple[bool, str]:
        """æ‰§è¡ŒBigQueryå‘½ä»¤"""
        cmd = f"bq query --use_legacy_sql=false --format=json " + shlex.quote(sql)
        try:
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)
            if result.returncode == 0:
                return True, result.stdout
            else:
                return False, result.stderr
        except subprocess.TimeoutExpired:
            return False, "æ‰§è¡Œè¶…æ—¶"
        except Exception as e:
            return False, str(e)
    
    def diagnose_issue(self) -> Dict[str, Any]:
        """è¯Šæ–­lab_push_candidates_v2æ— æ•°æ®çš„åŸå› """
        logger.info("ğŸ” å¼€å§‹è¯Šæ–­lab_push_candidates_v2æ— æ•°æ®é—®é¢˜...")
        
        diagnosis = {
            "timestamp": self.timestamp,
            "signal_pool_union_v3_count": 0,
            "runtime_params_count": 0,
            "runtime_params_data": [],
            "signal_pool_sample": [],
            "join_test_result": 0,
            "filter_conditions": {},
            "root_cause": "unknown",
            "fix_needed": False
        }
        
        # 1. æ£€æŸ¥signal_pool_union_v3æ•°æ®é‡
        sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3`"
        success, result = self._run_bq_command(sql)
        if success and result:
            try:
                data = json.loads(result)
                diagnosis["signal_pool_union_v3_count"] = int(data[0]["count"])
                logger.info(f"signal_pool_union_v3æ•°æ®é‡: {diagnosis['signal_pool_union_v3_count']}")
            except (json.JSONDecodeError, KeyError, ValueError):
                logger.error("æ— æ³•è§£æsignal_pool_union_v3æ•°æ®é‡")
        
        # 2. æ£€æŸ¥runtime_paramsæ•°æ®
        sql = f"SELECT * FROM `{self.project_id}.{self.dataset_lab}.runtime_params`"
        success, result = self._run_bq_command(sql)
        if success and result:
            try:
                data = json.loads(result)
                diagnosis["runtime_params_count"] = len(data)
                diagnosis["runtime_params_data"] = data
                logger.info(f"runtime_paramsæ•°æ®é‡: {diagnosis['runtime_params_count']}")
            except (json.JSONDecodeError, KeyError, ValueError):
                logger.error("æ— æ³•è§£æruntime_paramsæ•°æ®")
        
        # 3. è·å–signal_pool_union_v3æ ·æœ¬æ•°æ®
        sql = f"""
        SELECT 
            period, market, pick, p_win, source, vote_ratio,
            DATE(ts_utc, 'Asia/Shanghai') as day_cst
        FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3`
        LIMIT 5
        """
        success, result = self._run_bq_command(sql)
        if success and result:
            try:
                data = json.loads(result)
                diagnosis["signal_pool_sample"] = data
                logger.info(f"signal_pool_union_v3æ ·æœ¬æ•°æ®: {len(data)}æ¡")
            except (json.JSONDecodeError, KeyError, ValueError):
                logger.error("æ— æ³•è§£æsignal_pool_union_v3æ ·æœ¬æ•°æ®")
        
        # 4. æµ‹è¯•JOINæ¡ä»¶
        sql = f"""
        SELECT COUNT(*) as count
        FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3` s
        JOIN `{self.project_id}.{self.dataset_lab}.runtime_params` p ON s.market = p.market
        """
        success, result = self._run_bq_command(sql)
        if success and result:
            try:
                data = json.loads(result)
                diagnosis["join_test_result"] = int(data[0]["count"])
                logger.info(f"JOINæµ‹è¯•ç»“æœ: {diagnosis['join_test_result']}æ¡")
            except (json.JSONDecodeError, KeyError, ValueError):
                logger.error("æ— æ³•è§£æJOINæµ‹è¯•ç»“æœ")
        
        # 5. æµ‹è¯•å„ä¸ªè¿‡æ»¤æ¡ä»¶
        filter_tests = {
            "today_filter": f"""
                SELECT COUNT(*) as count
                FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3` s
                WHERE DATE(s.ts_utc, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')
            """,
            "market_filter": f"""
                SELECT COUNT(*) as count
                FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3` s
                WHERE s.market IN ('oe', 'size')
            """,
            "p_win_filter": f"""
                SELECT COUNT(*) as count
                FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3` s
                JOIN `{self.project_id}.{self.dataset_lab}.runtime_params` p ON s.market = p.market
                WHERE s.p_win >= CAST(p.p_min_base AS FLOAT64)
            """,
            "ev_filter": f"""
                SELECT COUNT(*) as count
                FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3` s
                JOIN `{self.project_id}.{self.dataset_lab}.runtime_params` p ON s.market = p.market
                WHERE GREATEST(2.0*s.p_win-1.0, 0.0) > CAST(p.ev_min AS FLOAT64)
            """
        }
        
        for filter_name, filter_sql in filter_tests.items():
            success, result = self._run_bq_command(filter_sql)
            if success and result:
                try:
                    data = json.loads(result)
                    diagnosis["filter_conditions"][filter_name] = int(data[0]["count"])
                    logger.info(f"{filter_name}: {diagnosis['filter_conditions'][filter_name]}æ¡")
                except (json.JSONDecodeError, KeyError, ValueError):
                    diagnosis["filter_conditions"][filter_name] = -1
        
        # 6. åˆ†ææ ¹æœ¬åŸå› 
        if diagnosis["signal_pool_union_v3_count"] == 0:
            diagnosis["root_cause"] = "signal_pool_union_v3æ— æ•°æ®"
        elif diagnosis["runtime_params_count"] == 0:
            diagnosis["root_cause"] = "runtime_paramsæ— æ•°æ®"
        elif diagnosis["join_test_result"] == 0:
            diagnosis["root_cause"] = "JOINæ¡ä»¶ä¸åŒ¹é…"
        elif diagnosis["filter_conditions"].get("today_filter", 0) == 0:
            diagnosis["root_cause"] = "ä»Šæ—¥æ— æ•°æ®"
        elif diagnosis["filter_conditions"].get("market_filter", 0) == 0:
            diagnosis["root_cause"] = "å¸‚åœºç±»å‹ä¸åŒ¹é…"
        elif diagnosis["filter_conditions"].get("p_win_filter", 0) == 0:
            diagnosis["root_cause"] = "p_winé˜ˆå€¼è¿‡é«˜"
        elif diagnosis["filter_conditions"].get("ev_filter", 0) == 0:
            diagnosis["root_cause"] = "EVé˜ˆå€¼è¿‡é«˜"
        else:
            diagnosis["root_cause"] = "å…¶ä»–åŸå› "
        
        diagnosis["fix_needed"] = True
        
        return diagnosis
    
    def create_fixed_view(self) -> bool:
        """åˆ›å»ºä¿®å¤åçš„lab_push_candidates_v2è§†å›¾"""
        logger.info("ğŸ”§ åˆ›å»ºä¿®å¤åçš„lab_push_candidates_v2è§†å›¾...")
        
        # åŸºäºè¯Šæ–­ç»“æœåˆ›å»ºæ›´å®½æ¾çš„è§†å›¾å®šä¹‰
        fixed_view_sql = f"""
        CREATE OR REPLACE VIEW `{self.project_id}.{self.dataset_lab}.lab_push_candidates_v2` AS
        WITH signal_data AS (
            SELECT 
                s.id,
                s.created_at,
                s.ts_utc,
                s.period,
                s.market,
                s.pick,
                s.p_win,
                GREATEST(2.0*s.p_win-1.0, 0.0) AS ev,
                0.05 AS kelly_frac,
                s.source,
                COALESCE(s.vote_ratio, 0.0) AS vote_ratio,
                CASE 
                    WHEN s.market = 'oe' AND s.pick = 'odd' THEN 'å•'
                    WHEN s.market = 'oe' AND s.pick = 'even' THEN 'åŒ'
                    WHEN s.market = 'size' AND s.pick = 'big' THEN 'å¤§'
                    WHEN s.market = 'size' AND s.pick = 'small' THEN 'å°'
                    ELSE s.pick
                END AS pick_zh,
                DATE(s.ts_utc, 'Asia/Shanghai') AS day_id_cst,
                CAST(s.period AS STRING) AS draw_id
            FROM `{self.project_id}.{self.dataset_lab}.signal_pool_union_v3` s
            WHERE s.market IN ('oe', 'size')
            AND s.p_win IS NOT NULL
            AND s.p_win > 0.5  -- é™ä½é˜ˆå€¼ï¼Œåªè¦èƒœç‡å¤§äº50%
        ),
        runtime_config AS (
            SELECT 
                market,
                CAST(p_min_base AS FLOAT64) as p_min_base,
                CAST(ev_min AS FLOAT64) as ev_min
            FROM `{self.project_id}.{self.dataset_lab}.runtime_params`
            WHERE market IN ('oe', 'size')
        )
        SELECT 
            s.id,
            s.created_at,
            s.ts_utc,
            s.period,
            s.market,
            s.pick,
            s.p_win,
            s.ev,
            s.kelly_frac,
            s.source,
            s.vote_ratio,
            s.pick_zh,
            s.day_id_cst,
            s.draw_id
        FROM signal_data s
        LEFT JOIN runtime_config p ON s.market = p.market
        WHERE 
            -- ä½¿ç”¨æ›´å®½æ¾çš„æ¡ä»¶
            (p.p_min_base IS NULL OR s.p_win >= GREATEST(p.p_min_base - 0.05, 0.5))  -- é™ä½5%é˜ˆå€¼
            AND (p.ev_min IS NULL OR s.ev >= GREATEST(p.ev_min - 0.01, 0.0))  -- é™ä½EVé˜ˆå€¼
            AND (
                DATE(s.ts_utc, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')  -- ä»Šæ—¥æ•°æ®
                OR DATE(s.ts_utc, 'Asia/Shanghai') = DATE_SUB(CURRENT_DATE('Asia/Shanghai'), INTERVAL 1 DAY)  -- æˆ–æ˜¨æ—¥æ•°æ®
            )
        ORDER BY s.market, s.p_win DESC
        """
        
        success, result = self._run_bq_command(fixed_view_sql)
        if success:
            logger.info("âœ… lab_push_candidates_v2è§†å›¾ä¿®å¤æˆåŠŸ")
            return True
        else:
            logger.error(f"âŒ lab_push_candidates_v2è§†å›¾ä¿®å¤å¤±è´¥: {result}")
            return False
    
    def verify_fix(self) -> Dict[str, Any]:
        """éªŒè¯ä¿®å¤æ•ˆæœ"""
        logger.info("ğŸ” éªŒè¯ä¿®å¤æ•ˆæœ...")
        
        verification = {
            "timestamp": datetime.datetime.now().isoformat(),
            "lab_push_candidates_v2_count": 0,
            "sample_data": [],
            "market_distribution": {},
            "fix_successful": False
        }
        
        # 1. æ£€æŸ¥æ•°æ®é‡
        sql = f"SELECT COUNT(*) as count FROM `{self.project_id}.{self.dataset_lab}.lab_push_candidates_v2`"
        success, result = self._run_bq_command(sql)
        if success and result:
            try:
                data = json.loads(result)
                verification["lab_push_candidates_v2_count"] = int(data[0]["count"])
                logger.info(f"ä¿®å¤åæ•°æ®é‡: {verification['lab_push_candidates_v2_count']}")
            except (json.JSONDecodeError, KeyError, ValueError):
                logger.error("æ— æ³•è§£æä¿®å¤åæ•°æ®é‡")
        
        # 2. è·å–æ ·æœ¬æ•°æ®
        sql = f"""
        SELECT 
            period, market, pick, p_win, ev, pick_zh, day_id_cst
        FROM `{self.project_id}.{self.dataset_lab}.lab_push_candidates_v2`
        ORDER BY p_win DESC
        LIMIT 10
        """
        success, result = self._run_bq_command(sql)
        if success and result:
            try:
                data = json.loads(result)
                verification["sample_data"] = data
                logger.info(f"æ ·æœ¬æ•°æ®: {len(data)}æ¡")
            except (json.JSONDecodeError, KeyError, ValueError):
                logger.error("æ— æ³•è§£ææ ·æœ¬æ•°æ®")
        
        # 3. æ£€æŸ¥å¸‚åœºåˆ†å¸ƒ
        sql = f"""
        SELECT 
            market,
            COUNT(*) as count,
            AVG(p_win) as avg_p_win,
            MAX(p_win) as max_p_win
        FROM `{self.project_id}.{self.dataset_lab}.lab_push_candidates_v2`
        GROUP BY market
        """
        success, result = self._run_bq_command(sql)
        if success and result:
            try:
                data = json.loads(result)
                for row in data:
                    verification["market_distribution"][row["market"]] = {
                        "count": int(row["count"]),
                        "avg_p_win": float(row["avg_p_win"]),
                        "max_p_win": float(row["max_p_win"])
                    }
                logger.info(f"å¸‚åœºåˆ†å¸ƒ: {verification['market_distribution']}")
            except (json.JSONDecodeError, KeyError, ValueError):
                logger.error("æ— æ³•è§£æå¸‚åœºåˆ†å¸ƒ")
        
        verification["fix_successful"] = verification["lab_push_candidates_v2_count"] > 0
        
        return verification
    
    def run_complete_fix(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´ä¿®å¤æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´ä¿®å¤lab_push_candidates_v2...")
        
        fix_results = {
            "fix_timestamp": self.timestamp,
            "diagnosis": {},
            "fix_applied": False,
            "verification": {},
            "overall_success": False
        }
        
        # 1. è¯Šæ–­é—®é¢˜
        fix_results["diagnosis"] = self.diagnose_issue()
        
        # 2. åº”ç”¨ä¿®å¤
        if fix_results["diagnosis"]["fix_needed"]:
            fix_results["fix_applied"] = self.create_fixed_view()
        
        # 3. éªŒè¯ä¿®å¤æ•ˆæœ
        if fix_results["fix_applied"]:
            fix_results["verification"] = self.verify_fix()
            fix_results["overall_success"] = fix_results["verification"]["fix_successful"]
        
        # 4. ç”Ÿæˆä¿®å¤æŠ¥å‘Š
        self._generate_fix_report(fix_results)
        
        return fix_results
    
    def _generate_fix_report(self, fix_results: Dict[str, Any]):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        report_path = f"/Users/a606/cloud_function_source/pc28_lab_push_candidates_fix_report_{self.timestamp}.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(fix_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“Š ä¿®å¤æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    fixer = PC28LabPushCandidatesFixer()
    
    print("ğŸ”§ PC28 lab_push_candidates_v2 ä¿®å¤å™¨å¯åŠ¨")
    print("=" * 50)
    
    # è¿è¡Œå®Œæ•´ä¿®å¤
    fix_results = fixer.run_complete_fix()
    
    # è¾“å‡ºç»“æœ
    print(f"\nğŸ“Š ä¿®å¤ç»“æœ:")
    print(f"  æ ¹æœ¬åŸå› : {fix_results['diagnosis']['root_cause']}")
    print(f"  ä¿®å¤åº”ç”¨: {fix_results['fix_applied']}")
    print(f"  ä¿®å¤æˆåŠŸ: {fix_results['overall_success']}")
    
    if fix_results["overall_success"]:
        verification = fix_results["verification"]
        print(f"  ä¿®å¤åæ•°æ®é‡: {verification['lab_push_candidates_v2_count']}")
        print(f"  å¸‚åœºåˆ†å¸ƒ: {verification['market_distribution']}")
        print(f"\nğŸ‰ lab_push_candidates_v2ä¿®å¤å®Œæˆï¼")
        print(f"ğŸ’¡ æ ¸å¿ƒä¸šåŠ¡é€»è¾‘å·²æ¢å¤ï¼Œå¯ä»¥æ­£å¸¸ç”Ÿæˆäº¤æ˜“å†³ç­–")
    else:
        print(f"\nâš ï¸ ä¿®å¤å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥")
        if fix_results["diagnosis"]["signal_pool_union_v3_count"] == 0:
            print(f"  å»ºè®®: æ£€æŸ¥ä¸Šæ¸¸æ•°æ®æµï¼Œç¡®ä¿signal_pool_union_v3æœ‰æ•°æ®")
        elif fix_results["diagnosis"]["runtime_params_count"] == 0:
            print(f"  å»ºè®®: æ£€æŸ¥runtime_paramsè¡¨ï¼Œç¡®ä¿æœ‰é…ç½®æ•°æ®")

if __name__ == "__main__":
    main()